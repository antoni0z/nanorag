[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "nbdev_rag",
    "section": "",
    "text": "This file will become your README and also the index of your documentation."
  },
  {
    "objectID": "index.html#install",
    "href": "index.html#install",
    "title": "nbdev_rag",
    "section": "Install",
    "text": "Install\npip install nbdev_rag"
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "nbdev_rag",
    "section": "How to use",
    "text": "How to use\nFill me in please! Donâ€™t forget code examples:\n\n1+1\n\n2"
  },
  {
    "objectID": "core.html",
    "href": "core.html",
    "title": "base",
    "section": "",
    "text": "source\n\nfoo\n\n foo ()"
  },
  {
    "objectID": "base.html",
    "href": "base.html",
    "title": "base",
    "section": "",
    "text": "source\n\nBaseNode\n\n BaseNode (metadata, model_context, prev_node=None, next_node=None,\n           parent_node=None, child_node=[], embedding=[])\n\nLowest level abstraction for storing interrelated pieces of information, building block for other types of nodes.\n\nsource\n\n\nTextNode\n\n TextNode (text, model_context, metadata, prev_node=None, next_node=None,\n           parent_node=None, child_node=[], embedding=[], auto_embed=True)\n\nClass for creating chunks of Text that contain additional information like relationships of metadata, inheritance from BaseNode but geared specifically towards text\n\nsource\n\n\nDocument\n\n Document (metadata={}, name=None, text=None, prev_node=None,\n           next_node=None, parent_node=None, child_node=[], embedding=[])\n\nClass that serves as a way to group information that comes from different sources intended to be stored or integrated with other services"
  },
  {
    "objectID": "utils.html",
    "href": "utils.html",
    "title": "Utils",
    "section": "",
    "text": "source\n\nhash_input\n\n hash_input (input_data:str)"
  },
  {
    "objectID": "Untitled.html",
    "href": "Untitled.html",
    "title": "nbdev_rag",
    "section": "",
    "text": "import torch\n\n\n\nclass LLM:\n    \"\"\"Class for interacting and Loading llms, tested with hugging face ones and it works correctly\"\"\"\n    def __init__(self, model, tokenizer):\n        self.model = model\n        self.tokenizer = tokenizer\n        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        self.model.to(self.device)\n\n    def __call__(self, prompt, max_length=100):\n        input_ids = self.tokenizer(prompt, return_tensors=\"pt\").input_ids.to(self.device)\n        output_ids = self.model.generate(input_ids=input_ids, max_length=max_length)\n        return self.tokenizer.decode(output_ids[0], skip_special_tokens=True).strip(prompt)\n\n\nclass PromptTemplate:\n    \"\"\"Class for prompt templating and adding intructions for an LLM\"\"\"\n    def __init__(self, template = 'A user provided this instructions'):\n        self.template = template\n\n    def __call__(self, input_text):\n        self.prompt = f\"{self.template}: {input_text} Output:\"\n        return self.prompt"
  },
  {
    "objectID": "04_llm.html",
    "href": "04_llm.html",
    "title": "nbdev_rag",
    "section": "",
    "text": "LLM\n\n LLM (model, tokenizer)\n\nClass for interacting and Loading llms, tested with hugging face ones and it works correctly\n\n\n\nPromptTemplate\n\n PromptTemplate (template='A user provided this instructions')\n\nClass for prompt templating and adding intructions for an LLM"
  },
  {
    "objectID": "store.html",
    "href": "store.html",
    "title": "Store",
    "section": "",
    "text": "class BaseDocumentStore(ABC):\n    \"\"\"\n    Base class for document storage\"\"\"\n    def __init__(self, documents : Dict[str, Document] = {}):\n        pass\n    @abstractmethod\n    def __call__(self, db): #Connect to backend and specific collection parameters\n        pass\n    @abstractmethod    \n    def add(self, document: Document, allow_duplicates = False):\n        pass\n    @abstractmethod \n    def ids(self):\n        pass\n    @abstractmethod    \n    def delete(self, ids: Union[List, str]):\n        pass\n    @abstractmethod\n    def get(self, ids: Union[UUID, List] = None):\n        pass\n\n\nclass DocumentStore(BaseDocumentStore):\n    \"\"\"Key value type document store that store documents by their id in a dictionary.\n    Also checks for duplicates via hashing and doesn't admit them\"\"\"\n    def __init__(self, documents : Dict[str, Document] = {}):\n        self.documents = documents\n\n    def __call__(self, db): #Connect to backend and specific collection parameters\n        pass\n        \n    def add(self, document: Document, allow_duplicates = False):\n        #Here check for docs with the same hash or id. If diff id and hash add\n        for stored_document in self.documents:\n            if self.documents[stored_document].hash == document.hash:\n                if allow_duplicates == True:\n                    self.documents[document.id] = document\n                    return f\"Document with duplicate hash {document.hash} has been added\"\n                return f\"You tried to add a duplicate document: {document.hash}\"\n            elif self.documents[stored_document].id == document.id:\n                self.documents[document.id] = document\n                return f\"Document with id {document.id} has been updated\"\n        self.documents[document.id] =  document\n\n    def ids(self):\n        doc_ids = [doc for doc in self.documents]\n        return doc_ids\n\n    def delete(self, ids: Union[List, str]):\n        deleted_docs = []\n        if isinstance(ids, List):\n            for id in ids:\n                deleted_doc = self.documents.pop(id, None)\n                if deleted_doc != None:\n                    deleted_docs.append(deleted_doc)\n        elif isinstance(ids, UUID):\n            deleted_doc = self.documents.pop(ids, None)\n            print(f'Ids are: {ids} and theoretically deleted doc is {deleted_doc}')\n            if deleted_doc != None:\n                deleted_docs.append(deleted_doc)\n        return f\"The following docs have been deleted {deleted_docs}\"\n        \n    def get(self, ids: Union[UUID, List] = None):\n        if ids == None:\n            ids = self.ids()\n        if isinstance(ids, List):\n            docs = [self.documents.get(id, None) for id in ids]\n            return docs\n        elif isinstance(ids, UUID):\n            return self.documents.get(ids, None)"
  },
  {
    "objectID": "context.html",
    "href": "context.html",
    "title": "Model Context",
    "section": "",
    "text": "source\n\nModelContext\n\n ModelContext (llm, embedding, tokenizer)\n\nInitialize self. See help(type(self)) for accurate signature."
  },
  {
    "objectID": "04_llms.html",
    "href": "04_llms.html",
    "title": "nbdev_rag",
    "section": "",
    "text": "import torch\n\n\n\nclass LLM:\n    \"\"\"Class for interacting and Loading llms, tested with hugging face ones and it works correctly\"\"\"\n    def __init__(self, model, tokenizer):\n        self.model = model\n        self.tokenizer = tokenizer\n        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        self.model.to(self.device)\n\n    def __call__(self, prompt, max_length=100):\n        input_ids = self.tokenizer(prompt, return_tensors=\"pt\").input_ids.to(self.device)\n        output_ids = self.model.generate(input_ids=input_ids, max_length=max_length)\n        return self.tokenizer.decode(output_ids[0], skip_special_tokens=True).strip(prompt)\n\n\nclass PromptTemplate:\n    \"\"\"Class for prompt templating and adding intructions for an LLM\"\"\"\n    def __init__(self, template = 'A user provided this instructions'):\n        self.template = template\n\n    def __call__(self, input_text):\n        self.prompt = f\"{self.template}: {input_text} Output:\"\n        return self.prompt"
  },
  {
    "objectID": "llm.html",
    "href": "llm.html",
    "title": "LLM",
    "section": "",
    "text": "source\n\nLLM\n\n LLM (model, tokenizer)\n\nClass for interacting and Loading llms, tested with hugging face ones and it works correctly\n\nsource\n\n\nPromptTemplate\n\n PromptTemplate (template='A user provided this instructions')\n\nClass for prompt templating and adding intructions for an LLM"
  }
]