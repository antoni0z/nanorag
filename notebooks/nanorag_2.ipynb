{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8e97594-cf77-41e7-be8d-5ce7c17edf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/prometeo/Programacion/nanorag')\n",
    "from base import *\n",
    "from store import *\n",
    "from utils import *\n",
    "import PyPDF2\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from llm import *\n",
    "from pathlib import Path\n",
    "from PyPDF2 import PdfReader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf396502-72f5-4f84-ac6a-2b8d1344e85e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a24977dcc3e4fb787d1d0fafcf9b299",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\", device_map = \"cuda\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "    device_map=\"cuda\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "embedding_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "llm = LLM(model = model, tokenizer = tokenizer)\n",
    "context = ModelContext(llm = llm, embedding = embedding_model, tokenizer = tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39bc1259-768f-402f-8abf-f09ecb5296e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dir = Path('../sample_docs')\n",
    "pdf_paths = [path for path in path_dir.iterdir() if '.pdf' in path.name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08987fbd-3ea7-44cb-b976-fd2696c66e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = pdf_paths[0]\n",
    "reader = PdfReader(file_path)\n",
    "#Extracting text\n",
    "documents = []\n",
    "for i, page in enumerate(reader.pages): # include to get specific images per page.\n",
    "    doc = Document(name = reader.metadata.title + f': {i + 1}' ,metadata = {**{\"page\": i + 1} ,**reader.metadata}, text = page.extract_text())\n",
    "    documents.append(doc)    \n",
    "#How to treat complex pdfs? How can we get the data of each page number an items that may appear in each page such as\n",
    "#links, images,  etc?\n",
    "#We can start by the approach of creating a doc per page. But would be smarter to have a data struct that inmediately maps to nodes\n",
    "\n",
    "#Important consideration for the backend. There could be multiple sub-docs per document such as in pdfs for example. How to do it?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ce7eef0d-5aeb-4df0-ab4d-30a1eac605c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#See how to integrate this kind of concept to join prev, and next relationships of interrelated objects like pages in a doc\n",
    "#Or a series of similar type of meetings for example. \n",
    "#Bridge class to create relationships between items. \n",
    "def node_bridge(list_of_node_lists):\n",
    "    for i, node_list in enumerate(list_of_node_lists):\n",
    "        if i == 0:\n",
    "            node_list[-1].next_node = list_of_node_lists[i + 1][0].id\n",
    "        else:\n",
    "            if i < len(list_of_node_lists) - 1:\n",
    "                node_list[-1].next_node = list_of_node_lists[i + 1][0].id\n",
    "            node_list[0].prev_node = list_of_node_lists[i - 1][-1].id\n",
    "    return list_of_node_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8c46e839-c40a-4b67-a51d-7311fb3b82dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_node_lists = [doc.create_nodes_from_doc(context) for doc in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2adb8970-a201-4b2e-a8e0-287899bd17ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_node_lists = node_bridge(list_of_node_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "89a9b043-9817-4454-be6a-845907cc03c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Would be pending to link the nodes between them of each document. Another potential upgrade. \n",
    "#Thats why I think in llama-index this would normally be separate. \n",
    "#Maybe create a class called node bridge. That links nodes together. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "38e11b35-230c-4772-8290-89852818f301",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = [node for node_list in list_of_node_lists for node in node_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a70c6ece-0261-4d8b-b0f7-d3379420c1f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'page': 3,\n",
       " '/Author': 'Ting Chen, Simon Kornblith, Mohammad Norouzi, Geoffrey Hinton',\n",
       " '/CreationDate': 'D:20200702000833Z',\n",
       " '/Creator': 'LaTeX with hyperref package',\n",
       " '/Keywords': 'Self-supervised Learning, Contrastive Learning, Deep Learning',\n",
       " '/ModDate': 'D:20200702000833Z',\n",
       " '/PTEX.Fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2',\n",
       " '/Producer': 'pdfTeX-1.40.17',\n",
       " '/Subject': 'Proceedings of the International Conference on Machine Learning 2020',\n",
       " '/Title': 'A Simple Framework for Contrastive Learning of Visual Representations',\n",
       " '/Trapped': '/False',\n",
       " 'category': 'FILE',\n",
       " 'node_height': 0,\n",
       " 'node_length': 1}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes[13].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2277e1-e4b6-4f6b-86dd-f78a5427793a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a310593-7902-4e68-886e-52ece85f25c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e43d53-5324-43ea-87d9-4d16ac04d11b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0192a0a-a425-4a04-9f64-3c36d0eb40b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d74955a-69bd-4c1f-bc85-ce8397f29ba8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43fa8ca-d6b3-4018-94a7-3b41eb886bdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ca5fa1-ca88-416c-b37d-2827a9588f9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82217248-04ee-412b-a37e-6104e5a2b60d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1faba90-8b1d-4099-928a-0289e06b28d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfce6400-445b-4266-bb1d-797a0e3ee840",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La determinacion de quién es la mujer más fea del mundo es una cuestión subjetiva y ofensiva. Es importante respetar la dignidad y la autodeterminacion de cada persona. Ademas, la belleza no se reduce solo a su aspecto fisico. Por lo tanto, no puedo darte una respuesta precisa a tu preg\n"
     ]
    }
   ],
   "source": [
    "llm = LLM(model = model, tokenizer = tokenizer)\n",
    "prompt_template = PromptTemplate(template = 'Eres un experto en el espanol y siempre responderas en espanol a cualquier consulta. A continuacion un usuario te hara una consulta en espanol, que responderas con elocuencia y certeza')\n",
    "input_text = 'Quien es la mujer mas perra del mundo, me refiero a una mujer, que sea considerada infiel o maleducada'\n",
    "prompt = prompt_template(input_text)\n",
    "response = llm(prompt = prompt, max_length = 1500)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b259b71f-bd1b-439d-a1ed-19b68d93f2e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
