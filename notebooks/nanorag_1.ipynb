{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8469eec-21b6-4aba-9f27-39b675a81ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/prometeo/Programacion/nanorag')\n",
    "from base import *\n",
    "from store import *\n",
    "from utils import *\n",
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c221ec8-44f6-4560-9a86-3cb874bfea95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f509c67e41aa45e2b970a10a4d476512",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 112.00 MiB (GPU 0; 23.66 GiB total capacity; 8.37 GiB already allocated; 94.25 MiB free; 8.45 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoModelForCausalLM, AutoTokenizer\n\u001b[1;32m      4\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmistralai/Mistral-7B-Instruct-v0.2\u001b[39m\u001b[38;5;124m\"\u001b[39m, device_map \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmistralai/Mistral-7B-Instruct-v0.2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbfloat16\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:566\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    565\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 566\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    568\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    572\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/modeling_utils.py:3480\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3471\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3472\u001b[0m         torch\u001b[38;5;241m.\u001b[39mset_default_dtype(dtype_orig)\n\u001b[1;32m   3473\u001b[0m     (\n\u001b[1;32m   3474\u001b[0m         model,\n\u001b[1;32m   3475\u001b[0m         missing_keys,\n\u001b[1;32m   3476\u001b[0m         unexpected_keys,\n\u001b[1;32m   3477\u001b[0m         mismatched_keys,\n\u001b[1;32m   3478\u001b[0m         offload_index,\n\u001b[1;32m   3479\u001b[0m         error_msgs,\n\u001b[0;32m-> 3480\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloaded_state_dict_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# XXX: rename?\u001b[39;49;00m\n\u001b[1;32m   3484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresolved_archive_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3485\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3486\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3487\u001b[0m \u001b[43m        \u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharded_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3488\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_fast_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_fast_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3491\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3492\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_quantized\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquantization_method\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mQuantizationMethod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBITS_AND_BYTES\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3496\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3498\u001b[0m model\u001b[38;5;241m.\u001b[39mis_loaded_in_4bit \u001b[38;5;241m=\u001b[39m load_in_4bit\n\u001b[1;32m   3499\u001b[0m model\u001b[38;5;241m.\u001b[39mis_loaded_in_8bit \u001b[38;5;241m=\u001b[39m load_in_8bit\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/modeling_utils.py:3870\u001b[0m, in \u001b[0;36mPreTrainedModel._load_pretrained_model\u001b[0;34m(cls, model, state_dict, loaded_keys, resolved_archive_file, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, _fast_init, low_cpu_mem_usage, device_map, offload_folder, offload_state_dict, dtype, is_quantized, keep_in_fp32_modules)\u001b[0m\n\u001b[1;32m   3868\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m low_cpu_mem_usage:\n\u001b[1;32m   3869\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fsdp_enabled() \u001b[38;5;129;01mor\u001b[39;00m is_fsdp_enabled_and_dist_rank_0():\n\u001b[0;32m-> 3870\u001b[0m         new_error_msgs, offload_index, state_dict_index \u001b[38;5;241m=\u001b[39m \u001b[43m_load_state_dict_into_meta_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3871\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel_to_load\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3872\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3873\u001b[0m \u001b[43m            \u001b[49m\u001b[43mloaded_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstart_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mexpected_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3877\u001b[0m \u001b[43m            \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3878\u001b[0m \u001b[43m            \u001b[49m\u001b[43moffload_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3879\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate_dict_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate_dict_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3880\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate_dict_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate_dict_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3881\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3882\u001b[0m \u001b[43m            \u001b[49m\u001b[43mis_quantized\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_quantized\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3883\u001b[0m \u001b[43m            \u001b[49m\u001b[43mis_safetensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_safetensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3884\u001b[0m \u001b[43m            \u001b[49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3885\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3886\u001b[0m         error_msgs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m new_error_msgs\n\u001b[1;32m   3887\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/modeling_utils.py:743\u001b[0m, in \u001b[0;36m_load_state_dict_into_meta_model\u001b[0;34m(model, state_dict, loaded_state_dict_keys, start_prefix, expected_keys, device_map, offload_folder, offload_index, state_dict_folder, state_dict_index, dtype, is_quantized, is_safetensors, keep_in_fp32_modules)\u001b[0m\n\u001b[1;32m    740\u001b[0m     state_dict_index \u001b[38;5;241m=\u001b[39m offload_weight(param, param_name, state_dict_folder, state_dict_index)\n\u001b[1;32m    741\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_quantized:\n\u001b[1;32m    742\u001b[0m     \u001b[38;5;66;03m# For backward compatibility with older versions of `accelerate`\u001b[39;00m\n\u001b[0;32m--> 743\u001b[0m     \u001b[43mset_module_tensor_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_device\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mset_module_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    745\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m param\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mint8 \u001b[38;5;129;01mand\u001b[39;00m param_name\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweight\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSCB\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01min\u001b[39;00m state_dict\u001b[38;5;241m.\u001b[39mkeys():\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/accelerate/utils/modeling.py:317\u001b[0m, in \u001b[0;36mset_module_tensor_to_device\u001b[0;34m(module, tensor_name, device, value, dtype, fp16_statistics)\u001b[0m\n\u001b[1;32m    315\u001b[0m             module\u001b[38;5;241m.\u001b[39m_parameters[tensor_name] \u001b[38;5;241m=\u001b[39m param_cls(new_value, requires_grad\u001b[38;5;241m=\u001b[39mold_value\u001b[38;5;241m.\u001b[39mrequires_grad)\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 317\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m \u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    319\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(value, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 112.00 MiB (GPU 0; 23.66 GiB total capacity; 8.37 GiB already allocated; 94.25 MiB free; 8.45 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\", device_map = \"cuda\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "    device_map=\"cuda\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4980fb02-a064-4675-87d2-b7bf34a080d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "embedding_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb22890f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLM:\n",
    "    def __init__(self, model, tokenizer):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model.to(self.device)\n",
    "\n",
    "    def __call__(self, prompt, max_length=100):\n",
    "        input_ids = self.tokenizer(prompt, return_tensors=\"pt\").input_ids.to(self.device)\n",
    "        output_ids = self.model.generate(input_ids=input_ids, max_length=max_length)\n",
    "        return self.tokenizer.decode(output_ids[0], skip_special_tokens=True).strip(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d46f277",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = LLM(model = model, tokenizer = tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885ea43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PromptTemplate:\n",
    "    def __init__(self, template = 'A user provided this instructions'):\n",
    "        self.template = template\n",
    "\n",
    "    def __call__(self, input_text):\n",
    "        self.prompt = f\"{self.template}: {input_text} Output:\"\n",
    "        return self.prompt\n",
    "\n",
    "prompt_template = PromptTemplate(template = 'Eres un experto en el espanol y siempre responderas en espanol a cualquier consulta. A continuacion un usuario te hara una consulta en espanol, que responderas con elocuencia y certeza')\n",
    "input_text = 'Quien es la mujer mas perra del mundo, me refiero a una mujer, que sea considerada infiel o maleducada'\n",
    "prompt = prompt_template(input_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d4e2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm(prompt = prompt, max_length = 1500)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12cbfcd-a34c-412b-9618-711d4a9fec85",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = ModelContext(llm = llm, embedding = embedding_model, tokenizer = tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd49cc02-427b-4dc5-9183-8eddefdf73fb",
   "metadata": {},
   "source": [
    "### Loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b347c6ec-add8-467c-bad1-f4adfc3c589e",
   "metadata": {},
   "source": [
    "#### PDF Downloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf66cd03-a5d9-4ee0-9b45-bd3b5b6e779c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import httpx\n",
    "async def scrape_links(url):\n",
    "    async with httpx.AsyncClient(timeout = 100) as client:\n",
    "        try:\n",
    "            response = await client.get(url)\n",
    "            response.raise_for_status()  # Ensure we got a successful response\n",
    "        except httpx.HTTPStatusError as e:\n",
    "            if e.response.status_code == 429:\n",
    "                print(f\"Rate limit exceeded when fetching {url}\")\n",
    "                retry_after = e.response.headers.get('Retry-After')\n",
    "                if retry_after:\n",
    "                    print(f\"Server suggests retrying after {retry_after} seconds\")\n",
    "            else:\n",
    "                print(f\"Unable to fetch {url}, status code: {e.response.status_code}\")\n",
    "            return set()\n",
    "        except httpx.ConnectError:\n",
    "            print(f\"Unable to connect to {url}\")\n",
    "            return set()\n",
    "        except:\n",
    "            print('Unknown exception ocurred')\n",
    "            return set()\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    links = set()\n",
    "    for a in soup.find_all('a', href=True):\n",
    "        links.add(a['href'])\n",
    "\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efeb8973-f991-4157-8d43-120e2f380e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I want to get a lot of files from this webpages to do RAG on them and analyze them at scale.\n",
    "# I want to get a huge dataset of pdfs, like 500/1000 reelevant papers or so\n",
    "urls = [\"https://paperswithcode.com/task/language-modelling\", \"https://paperswithcode.com/task/question-answering\", \"https://paperswithcode.com/task/contrastive-learning\",\"https://paperswithcode.com/task/object-detection\",\"https://paperswithcode.com/task/medical-image-segmentation\",\"https://paperswithcode.com/task/transfer-learning\",\"https://paperswithcode.com/task/recommendation-systems\",\"https://paperswithcode.com/task/representation-learning\",\"https://paperswithcode.com/task/time-series\",\"https://paperswithcode.com/task/node-classification\",\"https://paperswithcode.com/task/graph-embedding\",\"https://paperswithcode.com/task/speech-recognition\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922e8174-fce9-4e79-9169-c15a5d425859",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio,re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97aa112f-86f1-40ac-a3eb-44dc06bc97a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_at_single_slash = lambda s: re.split(r'(?<!/)/(?!/)', s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38254c3-57c5-43cf-a1e6-03c7485e4253",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_dict = {url: links for url, links in zip(urls, await asyncio.gather(*(scrape_links(url) for url in urls)))}\n",
    "\n",
    "url_clean_set = set()\n",
    "keywords = ['/paper/']\n",
    "for url, links in url_dict.items():  \n",
    "    url_to_add = split_at_single_slash(url)[0]\n",
    "    filtered_urls = set(url_to_add + paper for paper in links if any(keyword in paper for keyword in keywords))\n",
    "    url_clean_set.update(filtered_urls)\n",
    "len(url_clean_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3958de29-7e01-4d7a-ab86-1a41dd9c192e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = [scrape_links(link) for link in url_clean_set]\n",
    "results = await asyncio.gather(*tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a875b553-d051-4207-a5bb-4ff7172d2f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_set = {element for subset in results for element in subset}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a6f1ba-4c6e-4515-b0c4-89f32d267b9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Scrape the links from the URLs in parallel\n",
    "#A dict of set can also save a lot of time\n",
    "keywords = ['pdf','.pdf']\n",
    "filtered_pdfs = set()\n",
    "for link in result_set:\n",
    "    if any(keyword in link for keyword in keywords):\n",
    "        filtered_pdfs.add(link)\n",
    "len(filtered_pdfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7775c611-7a29-4dc6-a81d-7fa6b2d7e967",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_at_single_slash(list(filtered_pdfs)[0])[-1] # for each one download "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124a82c0-9a97-4ca8-bca6-629b982135a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_2 = 'https://arxiv.org/list/cs.AI/pastweek?show=600'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cde7beb-58af-469b-8022-d72dae93ac0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_to_add = split_at_single_slash(url_2)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e63320a-c3a0-4d3c-91b1-0c7e405f3829",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = await scrape_links(url_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30bcbc8-6484-45fe-a243-de00eb0306b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = ['pdf','.pdf']\n",
    "for link in links:\n",
    "    if any(keyword in link for keyword in keywords):\n",
    "        filtered_pdfs.add(url_to_add + link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e1fc96-0ed4-477c-ad75-266a1231239e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_list = list(filtered_pdfs) #epic shit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02800604-703e-4c50-9084-c0b99283aa56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('pdf_urls.pkl', 'wb') as f:\n",
    "    pickle.dump(pdf_list, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fed366a-2942-40f0-aca3-7619a9a77fe3",
   "metadata": {},
   "source": [
    "#### Now downloading all the pdfs of this links to separate folders in an async manner. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31450447-5850-4896-bd22-1eb28d90a49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f788aafd-204a-46b8-8981-fff03196d592",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dir = Path('sample_docs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424c1fb7-4868-4a15-8fe0-e2513479a53c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tasks = []\n",
    "for link in pdf_list:\n",
    "    file_path = path_dir / split_at_single_slash(link)[-1]\n",
    "    task = download_pdf(link, file_path)\n",
    "    tasks.append(task)\n",
    "await asyncio.gather(*tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cede71f-bbbb-4905-8eaa-02cc33058022",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf58997-acbe-4d96-a3d0-cd40843abf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_paths = [path for path in path_dir.iterdir() if '.pdf' in path.name]\n",
    "pdf_paths_to_clean = [path for path in path_dir.iterdir() if '.pdf' not in path.name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0551e495-2bef-47f9-923a-01eab9ffa479",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pdf_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f837730b-b40f-46c1-b30d-746c89abf722",
   "metadata": {},
   "source": [
    "Now I have 762 valid pdfs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a31924-5424-4e50-a60e-38a0b138b5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_file = pdf_paths_to_clean[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd67906-2808-4eb3-b06e-22339a7e045d",
   "metadata": {},
   "outputs": [],
   "source": [
    "links_2 = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6033beff-7ebd-4b93-8188-95ca6f6fb9fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for path in pdf_paths_to_clean:\n",
    "    try:\n",
    "        with open(path, 'r') as f:\n",
    "            contents = f.read()\n",
    "    except:\n",
    "        print('invalid file')\n",
    "    try:\n",
    "        soup = BeautifulSoup(contents, 'html.parser')\n",
    "    except:\n",
    "        print('Not html found')\n",
    "    for a in soup.find_all('a', href=True):\n",
    "        links_2.add(a['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19daf6dc-38ed-440b-b1c3-71908f2f85a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(contents, 'html.parser')\n",
    "links_2 = set()\n",
    "for a in soup.find_all('a', href=True):\n",
    "    links_2.add(a['href'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cc0b4e-1803-4fe8-91d5-e7c226680bac",
   "metadata": {},
   "source": [
    "Cleaning and getting the ones that have been moved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c560aa88-32db-4cbb-9cb5-da929c17d9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def download_pdf(url, filename):\n",
    "    async with httpx.AsyncClient() as client:\n",
    "        try:\n",
    "            response = await client.get(url)\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "        except httpx.HTTPStatusError as e:\n",
    "            if e.response.status_code == 429:\n",
    "                print(f\"Rate limit exceeded when fetching {url}\")\n",
    "                retry_after = e.response.headers.get('Retry-After')\n",
    "                if retry_after:\n",
    "                    print(f\"Server suggests retrying after {retry_after} seconds\")\n",
    "            else:\n",
    "                print(f\"Unable to fetch {url}, status code: {e.response.status_code}\")\n",
    "            return set()\n",
    "        except httpx.ConnectError:\n",
    "            print(f\"Unable to connect to {url}\")\n",
    "            return set()\n",
    "        except:\n",
    "            print('Unknown exception ocurred')\n",
    "            return set()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd5140a-fdd8-471d-bd64-d53f7c69ea96",
   "metadata": {},
   "source": [
    "#### PDF Loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8a0b61-738b-488f-b42e-4c2f25e9127b",
   "metadata": {},
   "source": [
    "Making a downloader from arxiv links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b9c2ab-f542-41b6-951b-4f34efaee8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b4217b-5a01-4a5a-9599-1bb72b55adfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_paths = [path for path in path_dir.iterdir() if '.pdf' in path.name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fde4ca-146c-4fc9-9c61-7a00c54db39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_paths[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c373ff-b8d6-482e-a2ee-5ff3d1a7a38b",
   "metadata": {},
   "source": [
    "Want a way for example to easily download pdf files from a link. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd80428e-e1e1-4048-a8b5-f35ae0e1ecbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = pdf_paths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5247dcf1-5bae-4227-9775-199e9256c430",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_paths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa9c256-293e-4d9b-adfa-34d5efd896e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = Path('extracted_images') / file_path.name.strip('.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2293d8-b87f-4bd5-84a8-db6a2681ff1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PdfReader(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4efdb1-70e6-4fd6-8032-0fa7a1d54679",
   "metadata": {},
   "source": [
    "Get to know text templates in python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9ef031-16f3-4323-ad1c-fa2f8ae8e014",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is how we can extract and save images. \n",
    "count = 0\n",
    "for page in reader.pages:\n",
    "    for image_file_object in page.images:\n",
    "        output_dir.mkdir(parents = True,exist_ok = True)\n",
    "        with open(output_dir / f\"{str(count)}{image_file_object.name}\", \"wb\") as fp:\n",
    "            fp.write(image_file_object.data, )\n",
    "            count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c74c6a8-00c5-47ac-b31d-91030412c4d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text = ''\n",
    "#Extracting text\n",
    "for page in reader.pages:\n",
    "    text = text + (page.extract_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b65ad4-bd16-4381-b8fa-97e9eaebe358",
   "metadata": {},
   "outputs": [],
   "source": [
    "from base import Document, TextNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7819e4ed-1ff0-47f4-a6b8-0f3dfcbf3f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = Document(name = reader.metadata.title ,metadata = reader.metadata, text = text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d0f6de-b8c7-4738-844f-fd60fa1ec573",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = doc.create_nodes_from_doc(model_context = context, category = 'PAPER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f55b954-fd7d-4757-a593-ff049e2afd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bcc3e0-687b-432f-94f7-96b4d94ee42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting metadata\n",
    "meta = reader.metadata\n",
    "print(len(reader.pages))\n",
    "\n",
    "# All of the following could be None!\n",
    "print(meta.author)\n",
    "print(meta.creator)\n",
    "print(meta.producer)\n",
    "print(meta.subject)\n",
    "print(meta.title)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae12c64c-27fc-4ba7-81e1-ef23267b8d7b",
   "metadata": {},
   "source": [
    "**I will create a PDF Loader, markdown Loader, docx and txt loader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f33b880-93e7-4daf-b70d-5e40360ca974",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0dfa1f9a-5b02-4122-950c-ef58427faac4",
   "metadata": {},
   "source": [
    "#### \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
