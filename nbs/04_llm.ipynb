{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36a8da5-4d71-4675-be11-99cb31acd3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486cb29d-6155-4ac7-99e4-c5ef313d6815",
   "metadata": {},
   "source": [
    "# LLM\n",
    "\n",
    "> Module for handling interactions with llms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0e1159-c4be-4f98-95db-ac962e321dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e6cff5-64b3-447d-9cba-ebee34493a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class LLM:\n",
    "    \"\"\"Class for interacting and Loading llms, tested with hugging face ones and it works correctly\"\"\"\n",
    "    def __init__(self, model, tokenizer):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model.to(self.device)\n",
    "\n",
    "    def __call__(self, prompt, max_length=100):\n",
    "        input_ids = self.tokenizer(prompt, return_tensors=\"pt\").input_ids.to(self.device)\n",
    "        output_ids = self.model.generate(input_ids=input_ids, max_length=max_length)\n",
    "        return self.tokenizer.decode(output_ids[0], skip_special_tokens=True).strip(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa6738e-1ba2-41d2-ba0f-1f44458f4d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class PromptTemplate:\n",
    "    \"\"\"Class for prompt templating and adding intructions for an LLM\"\"\"\n",
    "    def __init__(self, template = 'A user provided this instructions'):\n",
    "        self.template = template\n",
    "\n",
    "    def __call__(self, input_text):\n",
    "        self.prompt = f\"{self.template}: {input_text} Output:\"\n",
    "        return self.prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7266a200-83a3-4e33-8fbb-c59bedd046e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d403be-4d66-4bca-9256-8fe6e58ed380",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437e1473-2e23-4b7f-85ce-6effa012efec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319f7048-360c-4c7f-806d-4268141d035f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626a57bc-7ace-4e0b-bf65-d18f02ee6f3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aba81ee-1c77-4b5b-9827-e3d69a5c35ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47379802-62b3-4496-be0d-38b320fdf081",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
