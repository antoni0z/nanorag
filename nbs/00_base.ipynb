{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# base\n",
    "\n",
    "> Includes the main datastructures for Nodes and Documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from abc import ABC, abstractmethod\n",
    "import uuid\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from nanorag.utils import *\n",
    "from nanorag.context import *\n",
    "import polars as pl\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "DEFAULT_METADATA_TMPL = \"{key}: {value}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#TODO: Implement Reference to Vector Indices. \n",
    "class BaseNode(ABC):\n",
    "    \"\"\"\n",
    "    Lowest level abstraction for storing interrelated pieces of information, building block for other types of nodes. \n",
    "    \"\"\"\n",
    "    def __init__(self, metadata, model_context, prev_node=None, next_node=None, parent_node=None, child_node=[], embedding=[], id = None):\n",
    "        self.metadata = metadata\n",
    "        self.model_context = model_context\n",
    "        self.prev_node = prev_node  # In llama index they have relationships in one dict. I can try it.\n",
    "        self.next_node = next_node\n",
    "        self.parent_node = parent_node\n",
    "        self.child_node = child_node\n",
    "        self.embedding = embedding\n",
    "        if id == None:\n",
    "            self.id = self.__set_id()\n",
    "        else:\n",
    "            self.id = id\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"BaseNode(id={self.id}, metadata={self.metadata}, prev_node={self.prev_node}, next_node={self.next_node}, parent_node={self.parent_node}, child_node={self.child_node})\"\n",
    "\n",
    "    def __set_id(self):\n",
    "        return str(uuid.uuid4())\n",
    "\n",
    "    def create_embedding(self):\n",
    "        # Create embedding with the specific content inside.\n",
    "        pass\n",
    "    @abstractmethod\n",
    "    def get_embedding(self):\n",
    "        # Return the embeddings stored\n",
    "        pass\n",
    "    @abstractmethod\n",
    "    def get_metadata_str(self):\n",
    "        pass\n",
    "    @abstractmethod\n",
    "    def get_content(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class TextNode(BaseNode): #Add hash to verify content uniqueness\n",
    "    \"\"\"Class for creating chunks of Text that contain additional information like relationships of metadata, inheritance from\n",
    "    BaseNode but geared specifically towards text\"\"\"\n",
    "    #TODO: Include doc_id\n",
    "    def __init__(self, text, model_context, metadata, prev_node = None, next_node = None, parent_node = None, \n",
    "                 child_node = [], embedding = [], auto_embed = True, doc_id = None, source_id = None, id = None,\n",
    "                 idx_ref = None):\n",
    "        super().__init__(metadata = metadata, model_context = model_context, \n",
    "                         prev_node = prev_node, next_node = next_node, parent_node = parent_node, \n",
    "                         child_node = child_node, embedding = embedding, id = id)\n",
    "        self.text = text\n",
    "        self.model_context = model_context\n",
    "        self.embedding = None\n",
    "        if auto_embed == True:\n",
    "            self.create_embedding()\n",
    "        self.hash = self.__calculate_hash()\n",
    "        self.doc_id = doc_id\n",
    "        self.source_id = source_id\n",
    "        self.idx_ref = idx_ref\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"TextNode(id = {self.id},text = {self.text},metadata = {self.metadata}, prev_node = {self.prev_node}, next_node = {self.next_node}, parent_node = {self.parent_node}, child_node = {self.child_node})\"\n",
    "    \n",
    "    def create_embedding(self):\n",
    "        if self.embedding == None:\n",
    "            self.embedding = self.model_context.embedding.encode([self.text], normalize_embeddings = True) #Huggingface sentence transformers. #TODO: Generalize this, create wrapper.Embedding model would have get and create embedding.\n",
    "    def get_embedding(self):\n",
    "        if self.embedding is None:\n",
    "            raise ValueError(\"embedding not set.\")\n",
    "        return self.embedding\n",
    "        #Embedding for text. Try one for image.\n",
    "    def get_metadata_str(self, mode = None):\n",
    "        return '\\n'.join([DEFAULT_METADATA_TMPL.format(key=key, value=value) for key, value in self.metadata.items()])\n",
    "    def __calculate_hash(self):\n",
    "        return hash_input(f\"{self.text}{self.metadata}{self.prev_node}{self.next_node}{self.parent_node}{self.child_node}\")\n",
    "    def get_content(self, metadata_mode = None):\n",
    "        return self.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Document(BaseNode): \n",
    "    # A document is a collection of nodes. Add hash to verify content uniqueness.\n",
    "    # Also can be the source of information.\n",
    "    \"\"\"\n",
    "    Class that serves as a way to group information that comes from different sources intended to be stored or integrated with other services. It serves\n",
    "    as the centralized source of truth of the information that is transformed into nodes. It can be used to store the information of a document, a webpage, pdf\n",
    "    or any other source of information. The hash is recalculated once the info is changed and serves as an interface to docstore. \n",
    "    \"\"\"\n",
    "    def __init__(self, metadata = {}, name = None, text = None, prev_node = None, \n",
    "                 next_node = None, parent_node = None, child_node = [], \n",
    "                 embedding = [], source_id = None, doc_separator = None, \n",
    "                 id = None, nodes = [], store = None):\n",
    "        self._initialized = False\n",
    "        super().__init__(metadata = metadata, prev_node = prev_node, next_node = next_node, parent_node = parent_node, child_node = child_node, embedding = embedding, model_context=None, id = id) \n",
    "        self._text = text\n",
    "        self._name = name\n",
    "        self._metadata = metadata\n",
    "        if source_id == None:\n",
    "            self.source_id = self.__set_id()\n",
    "        else:\n",
    "            self.source_id = source_id\n",
    "        self._source_id = self.source_id\n",
    "        self.nodes = nodes\n",
    "        self.doc_separator = doc_separator\n",
    "        self.hash = self.__calculate_hash()\n",
    "        self._initialized = True\n",
    "        self.store = store\n",
    "\n",
    "    @property\n",
    "    def id_(self):\n",
    "        return str(self.id)\n",
    "\n",
    "    @property\n",
    "    def text(self):\n",
    "        return self._text\n",
    "\n",
    "    @text.setter\n",
    "    def text(self, value):\n",
    "        self._text = value\n",
    "        if self._initialized:\n",
    "            self.hash = self.__update_hash()\n",
    "\n",
    "    @property\n",
    "    def name(self):\n",
    "        return self._name\n",
    "\n",
    "    @name.setter\n",
    "    def name(self, value):\n",
    "        self._name = value\n",
    "        if self._initialized:\n",
    "            self.hash = self.__update_hash()\n",
    "\n",
    "    @property\n",
    "    def metadata(self):\n",
    "        return self._metadata\n",
    "\n",
    "    @metadata.setter\n",
    "    def metadata(self, value):\n",
    "        self._metadata = value\n",
    "        if self._initialized:\n",
    "            self.hash = self.__update_hash()\n",
    "\n",
    "    @property\n",
    "    def source_id(self):\n",
    "        return self._source_id\n",
    "    \n",
    "    @source_id.setter\n",
    "    def source_id(self, value):\n",
    "        self._source_id = value\n",
    "        if self._initialized:\n",
    "            self.hash = self.__update_hash()\n",
    "\n",
    "    def __update_hash(self):\n",
    "        \"\"\"Recalculated if name, metadata, text or source id are modified.\"\"\"\n",
    "        return hash_input(f\"{self._name}{self._metadata}{self._text}{self.source_id}\")\n",
    "\n",
    "    def __calculate_hash(self):\n",
    "        \"\"\"Calculated at the start with name, metadata, text and source id.\"\"\"\n",
    "        return hash_input(f\"{self.name}{self.metadata}{self.text}{self.source_id}\")\n",
    "    \n",
    "    def __repr__(self):\n",
    "      return f\"Document(id = {self.id}, name = {self.name}, metadata = {self.metadata}, source_id = {self.source_id})\"\n",
    "\n",
    "    def __set_id(self):\n",
    "        return str(uuid.uuid4())\n",
    "\n",
    "    def get_embedding(self):\n",
    "        #Return the embedding of the nodes\n",
    "        pass\n",
    "    \n",
    "    #TODO: Substitute func for class that manages the transformation into Nodes. \n",
    "    def create_nodes_from_doc(self,model_context, chunk_size = 1024): #TODO: Support adding new full metadata\n",
    "        nodes = []\n",
    "        chunked_text = self.__chunk_text(chunk_size)\n",
    "        existing_metadata = self.metadata\n",
    "        existing_metadata['doc_name'] = self.name\n",
    "        for i, text in enumerate(chunked_text):\n",
    "            if i == 0:\n",
    "                 node_metadata = {**existing_metadata,**{'node_height': 0, 'node_length':1}}\n",
    "                 nodes.append(TextNode(text = text, metadata = node_metadata, model_context = model_context, doc_id=self.id, source_id=self.source_id))\n",
    "            else:\n",
    "                 node_metadata = {**existing_metadata,**{'node_height': 0, 'node_length':1}}\n",
    "                 node = TextNode(text = text, metadata = node_metadata, model_context = model_context, prev_node =  nodes[i - 1].id, doc_id=self.id, source_id=self.source_id)\n",
    "                 nodes.append(node)\n",
    "                 nodes[i - 1].next_node = node.id\n",
    "        return nodes\n",
    "        \n",
    "    def __chunk_text(self, chunk_size = 1024): #Make with other types of text representations like dataframes. Initial version.\n",
    "        chunked_text = []\n",
    "        text = self.text\n",
    "        for i in range(0, len(text), chunk_size):\n",
    "            chunked_text.append(text[i:chunk_size + i])\n",
    "        return chunked_text\n",
    "    \n",
    "    def copy(self):\n",
    "        cls = self.__class__\n",
    "        result = cls.__new__(cls)\n",
    "        result.__dict__.update(self.__dict__)\n",
    "        return result\n",
    "    def get_metadata_str(self, mode = None):\n",
    "        return '\\n'.join([DEFAULT_METADATA_TMPL.format(key=key, value=value) for key, value in self.metadata.items()])\n",
    "    \n",
    "    def save(self):\n",
    "        self.store.add(self)\n",
    "\n",
    "    def delete(self):\n",
    "        self.store.delete(self)\n",
    "        \n",
    "    def get_content(self, metadata_mode = None):\n",
    "        return self.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#TODO: Make sure model context is preserved, do a conversion for users to be able to load from huggingface as they make the index. \n",
    "#First supporting adding Nodes. Then plan to add docs and dfs to add. \n",
    "class TableIndex: #I \n",
    "    \"\"\"Table for representing data to analyze. Rows can be added a single class groups all its needed for llm context. Acts as a node store and can be stored on pillow format. Another diff paradigm for more distributes info structure. \n",
    "    Nodes can be inserted. Or docs can be converted to nodes and inserted.  Can have interop with duckdb thanks to arrow format. By default add class supports adding new nodes or dfs to the table index.\"\"\"\n",
    "    #Can be initialized with just a df. Can convert with the bridge. With the bridge, do checks between diff object and autodetect which to convert to nodes, docs, subdocs or polars df. \n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        #Here the conversion to df happens.\n",
    "    def add(self, nodes: List[TextNode]):\n",
    "        df = self.convert_nodes_to_df(nodes)\n",
    "        self.df = self.df.vstack(df)\n",
    "\n",
    "    #Support different queries. Method to get the diff cols and visualize. \n",
    "    def add_column(self):\n",
    "        pass\n",
    "    def get_content(self): #Here would have to do a kind or select or something like that if big. \n",
    "        pass\n",
    "    def get_embedding(self):  #Same here\n",
    "        pass\n",
    "    def get_metadata_str(self):\n",
    "        pass\n",
    "    \n",
    "    @staticmethod\n",
    "    def safe_getattr(node, attr, default=None):\n",
    "        try:\n",
    "            return getattr(node, attr)\n",
    "        except AttributeError:\n",
    "            return default\n",
    "        \n",
    "    @staticmethod\n",
    "    def convert_nodes_to_df(nodes):\n",
    "        node_data = {}\n",
    "        for key in nodes[0].metadata.keys():\n",
    "            node_data[key] = []\n",
    "\n",
    "        for node in nodes:\n",
    "            for key in node_data.keys():\n",
    "                node_data[key].append(node.metadata.get(key, None))\n",
    "\n",
    "        node_attributes = [\"id\",\"text\", \"hash\", \"embedding\", \"doc_id\", \"source_id\", \"model_context\", \"prev_node\", \"next_node\", \"child_node\", \"parent_node\"]\n",
    "\n",
    "        for attr in node_attributes:\n",
    "            if attr == 'embedding':\n",
    "                node_data[attr] = [TableIndex.safe_getattr(node, attr[0], None) for node in nodes]\n",
    "                continue\n",
    "            node_data[attr] = [TableIndex.safe_getattr(node, attr, None) for node in nodes]\n",
    "        return pl.DataFrame(node_data)\n",
    "    \n",
    "    @classmethod \n",
    "    def from_nodes(cls, nodes):\n",
    "        df = cls.convert_nodes_to_df(nodes)\n",
    "        return cls(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0c888e2f5584a91b7fd316774d0aade",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| hide \n",
    "#| eval: false\n",
    "context = ModelContext()\n",
    "context.set_default()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide \n",
    "#| eval: false\n",
    "from nanorag.loaders import PDFLoader, DocumentBridge\n",
    "loader = PDFLoader('datasets/papers_pdf')\n",
    "documents = loader.get_documents()\n",
    "nodes = DocumentBridge(documents, context = context).to_nodes()\n",
    "len(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "#| eval: false\n",
    "loader = PDFLoader('datasets/papers_pdf')\n",
    "documents = loader.get_documents()\n",
    "index = TableIndex.from_nodes(nodes)\n",
    "nodes = DocumentBridge(documents, context = context).to_nodes()\n",
    "index.add(nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imagining that there is a list of Nodes, for the first case. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Create struct to handle dfs under the hood. Using polars.\n",
    "\n",
    "* Allow switch back and force from nodes to dataframes for things like time sorting or other strategies that can be tried out for retrieval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need keys to look for that a TextNode could have to add it to a df. \n",
    "\n",
    "Each key of the metadata must be converted to other value. We will convert every column that actually exists\n",
    "\n",
    "See how to make it accept nodes and documents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "#| eval: false\n",
    "import random\n",
    "# Replace 'nodes_length' with the actual number of nodes you have: len(nodes)\n",
    "nodes_length = len(nodes)\n",
    "\n",
    "# Generate random sentiment data\n",
    "positive_sentiment = [random.random() for _ in range(nodes_length)]\n",
    "neutral_sentiment = [random.random() for _ in range(nodes_length)]\n",
    "negative_sentiment = [random.random() for _ in range(nodes_length)]\n",
    "\n",
    "# Normalize the sentiment scores such that for each node they sum up to 1\n",
    "normalized_positive = [p / (p + n + nu) for p, n, nu in zip(positive_sentiment, neutral_sentiment, negative_sentiment)]\n",
    "normalized_neutral = [nu / (p + n + nu) for p, n, nu in zip(positive_sentiment, neutral_sentiment, negative_sentiment)]\n",
    "normalized_negative = [n / (p + n + nu) for p, n, nu in zip(positive_sentiment, neutral_sentiment, negative_sentiment)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The TableIndex is both the struct and the index, an hybrid that can serve for distributed storage as pillow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 26)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>page</th><th>category</th><th>/Title</th><th>/Author</th><th>/Subject</th><th>/Creator</th><th>/Producer</th><th>/Creation_date</th><th>/Modification_date</th><th>file_path</th><th>file_name</th><th>/SystemInfo</th><th>doc_name</th><th>node_height</th><th>node_length</th><th>id</th><th>text</th><th>hash</th><th>embedding</th><th>doc_id</th><th>source_id</th><th>model_context</th><th>prev_node</th><th>next_node</th><th>child_node</th><th>parent_node</th></tr><tr><td>i64</td><td>str</td><td>null</td><td>str</td><td>str</td><td>str</td><td>str</td><td>datetime[μs, UTC]</td><td>datetime[μs, UTC]</td><td>object</td><td>str</td><td>struct[2]</td><td>str</td><td>i64</td><td>i64</td><td>str</td><td>str</td><td>str</td><td>null</td><td>str</td><td>str</td><td>object</td><td>str</td><td>str</td><td>list[null]</td><td>null</td></tr></thead><tbody><tr><td>1</td><td>&quot;PDF&quot;</td><td>null</td><td>&quot;&quot;</td><td>&quot;&quot;</td><td>&quot;LaTeX with hyp…</td><td>&quot;pdfTeX-1.40.25…</td><td>2023-12-20 02:33:36 UTC</td><td>2023-12-20 02:33:36 UTC</td><td>datasets/papers_pdf/2312.11819.pdf</td><td>&quot;2312.11819.pdf…</td><td>{&quot;Linux&quot;,&quot;/home/prometeo/Programacion/nanorag/nbs&quot;}</td><td>&quot;An Adaptive Pl…</td><td>0</td><td>1</td><td>&quot;a6474607-1770-…</td><td>&quot;An Adaptive Pl…</td><td>&quot;03c711d43291de…</td><td>null</td><td>&quot;68dc524f-adac-…</td><td>&quot;10b2ecc6-4af3-…</td><td>&lt;nanorag.context.ModelContext object at 0x7fa123016e60&gt;</td><td>null</td><td>&quot;c9cf5148-e465-…</td><td>[]</td><td>null</td></tr><tr><td>1</td><td>&quot;PDF&quot;</td><td>null</td><td>&quot;&quot;</td><td>&quot;&quot;</td><td>&quot;LaTeX with hyp…</td><td>&quot;pdfTeX-1.40.25…</td><td>2023-12-20 02:33:36 UTC</td><td>2023-12-20 02:33:36 UTC</td><td>datasets/papers_pdf/2312.11819.pdf</td><td>&quot;2312.11819.pdf…</td><td>{&quot;Linux&quot;,&quot;/home/prometeo/Programacion/nanorag/nbs&quot;}</td><td>&quot;An Adaptive Pl…</td><td>0</td><td>1</td><td>&quot;721fa0d8-c8a0-…</td><td>&quot;n@antfin.com).…</td><td>&quot;adfd5d17f5cc48…</td><td>null</td><td>&quot;68dc524f-adac-…</td><td>&quot;10b2ecc6-4af3-…</td><td>&lt;nanorag.context.ModelContext object at 0x7fa123016e60&gt;</td><td>&quot;bd4f06ee-859d-…</td><td>&quot;f54f0490-cf63-…</td><td>[]</td><td>null</td></tr><tr><td>13</td><td>&quot;PDF&quot;</td><td>null</td><td>&quot;&quot;</td><td>&quot;&quot;</td><td>&quot;LaTeX with hyp…</td><td>&quot;pdfTeX-1.40.25…</td><td>2023-12-20 02:33:36 UTC</td><td>2023-12-20 02:33:36 UTC</td><td>datasets/papers_pdf/2312.11819.pdf</td><td>&quot;2312.11819.pdf…</td><td>{&quot;Linux&quot;,&quot;/home/prometeo/Programacion/nanorag/nbs&quot;}</td><td>&quot;An Adaptive Pl…</td><td>0</td><td>1</td><td>&quot;6635fc95-07f3-…</td><td>&quot;ebastian Borge…</td><td>&quot;4e7e45a71cbff4…</td><td>null</td><td>&quot;e66f2aeb-8b27-…</td><td>&quot;10b2ecc6-4af3-…</td><td>&lt;nanorag.context.ModelContext object at 0x7fa123016e60&gt;</td><td>&quot;32f5472a-fcc6-…</td><td>&quot;768cb31d-a3a8-…</td><td>[]</td><td>null</td></tr><tr><td>1</td><td>&quot;PDF&quot;</td><td>null</td><td>null</td><td>null</td><td>&quot;TeX&quot;</td><td>&quot;pdfTeX-1.40.25…</td><td>2023-12-20 02:45:20 UTC</td><td>2023-12-20 02:45:20 UTC</td><td>datasets/papers_pdf/2312.12341.pdf</td><td>&quot;2312.12341.pdf…</td><td>{&quot;Linux&quot;,&quot;/home/prometeo/Programacion/nanorag/nbs&quot;}</td><td>&quot;Engineering an…</td><td>0</td><td>1</td><td>&quot;9e7ebb0b-bebf-…</td><td>&quot;Engineering an…</td><td>&quot;f0282e4bd0081a…</td><td>null</td><td>&quot;ff423c9f-2d0f-…</td><td>&quot;ee72f29e-6c6c-…</td><td>&lt;nanorag.context.ModelContext object at 0x7fa123016e60&gt;</td><td>null</td><td>&quot;960d75d2-c99e-…</td><td>[]</td><td>null</td></tr><tr><td>1</td><td>&quot;PDF&quot;</td><td>null</td><td>null</td><td>null</td><td>&quot;TeX&quot;</td><td>&quot;pdfTeX-1.40.25…</td><td>2023-12-20 02:45:20 UTC</td><td>2023-12-20 02:45:20 UTC</td><td>datasets/papers_pdf/2312.12341.pdf</td><td>&quot;2312.12341.pdf…</td><td>{&quot;Linux&quot;,&quot;/home/prometeo/Programacion/nanorag/nbs&quot;}</td><td>&quot;Engineering an…</td><td>0</td><td>1</td><td>&quot;7fa8e5e2-b983-…</td><td>&quot; [cs.AI]  19 D…</td><td>&quot;785316a8bba862…</td><td>null</td><td>&quot;ff423c9f-2d0f-…</td><td>&quot;ee72f29e-6c6c-…</td><td>&lt;nanorag.context.ModelContext object at 0x7fa123016e60&gt;</td><td>&quot;c7133fb8-ad2b-…</td><td>&quot;c38449e8-5632-…</td><td>[]</td><td>null</td></tr><tr><td>8</td><td>&quot;PDF&quot;</td><td>null</td><td>null</td><td>null</td><td>&quot;TeX&quot;</td><td>&quot;pdfTeX-1.40.25…</td><td>2023-12-20 02:45:20 UTC</td><td>2023-12-20 02:45:20 UTC</td><td>datasets/papers_pdf/2312.12341.pdf</td><td>&quot;2312.12341.pdf…</td><td>{&quot;Linux&quot;,&quot;/home/prometeo/Programacion/nanorag/nbs&quot;}</td><td>&quot;Engineering an…</td><td>0</td><td>1</td><td>&quot;c1d1eeac-a8c8-…</td><td>&quot;Jiong Yang for…</td><td>&quot;b4e483cd709d38…</td><td>null</td><td>&quot;3e98ef95-319d-…</td><td>&quot;ee72f29e-6c6c-…</td><td>&lt;nanorag.context.ModelContext object at 0x7fa123016e60&gt;</td><td>&quot;08ce92c5-0b48-…</td><td>&quot;a3de552a-f9ac-…</td><td>[]</td><td>null</td></tr><tr><td>8</td><td>&quot;PDF&quot;</td><td>null</td><td>null</td><td>null</td><td>&quot;TeX&quot;</td><td>&quot;pdfTeX-1.40.25…</td><td>2023-12-20 02:45:20 UTC</td><td>2023-12-20 02:45:20 UTC</td><td>datasets/papers_pdf/2312.12341.pdf</td><td>&quot;2312.12341.pdf…</td><td>{&quot;Linux&quot;,&quot;/home/prometeo/Programacion/nanorag/nbs&quot;}</td><td>&quot;Engineering an…</td><td>0</td><td>1</td><td>&quot;ddfd1e4c-48ae-…</td><td>&quot;ledge Represen…</td><td>&quot;62777916488cc4…</td><td>null</td><td>&quot;3e98ef95-319d-…</td><td>&quot;ee72f29e-6c6c-…</td><td>&lt;nanorag.context.ModelContext object at 0x7fa123016e60&gt;</td><td>&quot;a3de552a-f9ac-…</td><td>&quot;1965b41e-80e1-…</td><td>[]</td><td>null</td></tr><tr><td>8</td><td>&quot;PDF&quot;</td><td>null</td><td>null</td><td>null</td><td>&quot;TeX&quot;</td><td>&quot;pdfTeX-1.40.25…</td><td>2023-12-20 02:45:20 UTC</td><td>2023-12-20 02:45:20 UTC</td><td>datasets/papers_pdf/2312.12341.pdf</td><td>&quot;2312.12341.pdf…</td><td>{&quot;Linux&quot;,&quot;/home/prometeo/Programacion/nanorag/nbs&quot;}</td><td>&quot;Engineering an…</td><td>0</td><td>1</td><td>&quot;1965b41e-80e1-…</td><td>&quot; Log. Program.…</td><td>&quot;422afde3474775…</td><td>null</td><td>&quot;3e98ef95-319d-…</td><td>&quot;ee72f29e-6c6c-…</td><td>&lt;nanorag.context.ModelContext object at 0x7fa123016e60&gt;</td><td>&quot;ddfd1e4c-48ae-…</td><td>&quot;b63d4e93-40db-…</td><td>[]</td><td>null</td></tr><tr><td>8</td><td>&quot;PDF&quot;</td><td>null</td><td>null</td><td>null</td><td>&quot;TeX&quot;</td><td>&quot;pdfTeX-1.40.25…</td><td>2023-12-20 02:45:20 UTC</td><td>2023-12-20 02:45:20 UTC</td><td>datasets/papers_pdf/2312.12341.pdf</td><td>&quot;2312.12341.pdf…</td><td>{&quot;Linux&quot;,&quot;/home/prometeo/Programacion/nanorag/nbs&quot;}</td><td>&quot;Engineering an…</td><td>0</td><td>1</td><td>&quot;b63d4e93-40db-…</td><td>&quot;s.Computer Aid…</td><td>&quot;62a30cb9520d73…</td><td>null</td><td>&quot;3e98ef95-319d-…</td><td>&quot;ee72f29e-6c6c-…</td><td>&lt;nanorag.context.ModelContext object at 0x7fa123016e60&gt;</td><td>&quot;1965b41e-80e1-…</td><td>&quot;f26c7a1f-7bab-…</td><td>[]</td><td>null</td></tr><tr><td>9</td><td>&quot;PDF&quot;</td><td>null</td><td>null</td><td>null</td><td>&quot;TeX&quot;</td><td>&quot;pdfTeX-1.40.25…</td><td>2023-12-20 02:45:20 UTC</td><td>2023-12-20 02:45:20 UTC</td><td>datasets/papers_pdf/2312.12341.pdf</td><td>&quot;2312.12341.pdf…</td><td>{&quot;Linux&quot;,&quot;/home/prometeo/Programacion/nanorag/nbs&quot;}</td><td>&quot;Engineering an…</td><td>0</td><td>1</td><td>&quot;742cd3fd-1455-…</td><td>&quot;Ryosuke Suzuki…</td><td>&quot;f0aa86ca099b44…</td><td>null</td><td>&quot;158295cf-9c56-…</td><td>&quot;ee72f29e-6c6c-…</td><td>&lt;nanorag.context.ModelContext object at 0x7fa123016e60&gt;</td><td>&quot;f26c7a1f-7bab-…</td><td>&quot;634b20e4-f2d0-…</td><td>[]</td><td>null</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10, 26)\n",
       "┌──────┬──────────┬────────┬─────────┬───┬───────────────┬──────────────┬────────────┬─────────────┐\n",
       "│ page ┆ category ┆ /Title ┆ /Author ┆ … ┆ prev_node     ┆ next_node    ┆ child_node ┆ parent_node │\n",
       "│ ---  ┆ ---      ┆ ---    ┆ ---     ┆   ┆ ---           ┆ ---          ┆ ---        ┆ ---         │\n",
       "│ i64  ┆ str      ┆ null   ┆ str     ┆   ┆ str           ┆ str          ┆ list[null] ┆ null        │\n",
       "╞══════╪══════════╪════════╪═════════╪═══╪═══════════════╪══════════════╪════════════╪═════════════╡\n",
       "│ 1    ┆ PDF      ┆ null   ┆         ┆ … ┆ null          ┆ c9cf5148-e46 ┆ []         ┆ null        │\n",
       "│      ┆          ┆        ┆         ┆   ┆               ┆ 5-416d-a44d- ┆            ┆             │\n",
       "│      ┆          ┆        ┆         ┆   ┆               ┆ 08d3650b…    ┆            ┆             │\n",
       "│ 1    ┆ PDF      ┆ null   ┆         ┆ … ┆ bd4f06ee-859d ┆ f54f0490-cf6 ┆ []         ┆ null        │\n",
       "│      ┆          ┆        ┆         ┆   ┆ -43b7-bdce-f5 ┆ 3-4eb9-90b2- ┆            ┆             │\n",
       "│      ┆          ┆        ┆         ┆   ┆ 49becc…       ┆ 997adee7…    ┆            ┆             │\n",
       "│ 13   ┆ PDF      ┆ null   ┆         ┆ … ┆ 32f5472a-fcc6 ┆ 768cb31d-a3a ┆ []         ┆ null        │\n",
       "│      ┆          ┆        ┆         ┆   ┆ -4e93-895a-72 ┆ 8-42c4-ab64- ┆            ┆             │\n",
       "│      ┆          ┆        ┆         ┆   ┆ 520b41…       ┆ 24088648…    ┆            ┆             │\n",
       "│ 1    ┆ PDF      ┆ null   ┆ null    ┆ … ┆ null          ┆ 960d75d2-c99 ┆ []         ┆ null        │\n",
       "│      ┆          ┆        ┆         ┆   ┆               ┆ e-46ed-83d0- ┆            ┆             │\n",
       "│      ┆          ┆        ┆         ┆   ┆               ┆ 04d8f060…    ┆            ┆             │\n",
       "│ 1    ┆ PDF      ┆ null   ┆ null    ┆ … ┆ c7133fb8-ad2b ┆ c38449e8-563 ┆ []         ┆ null        │\n",
       "│      ┆          ┆        ┆         ┆   ┆ -4238-bdf4-8f ┆ 2-42fd-914e- ┆            ┆             │\n",
       "│      ┆          ┆        ┆         ┆   ┆ 1be912…       ┆ 5139a88a…    ┆            ┆             │\n",
       "│ 8    ┆ PDF      ┆ null   ┆ null    ┆ … ┆ 08ce92c5-0b48 ┆ a3de552a-f9a ┆ []         ┆ null        │\n",
       "│      ┆          ┆        ┆         ┆   ┆ -4e8c-a70e-4d ┆ c-4358-81c5- ┆            ┆             │\n",
       "│      ┆          ┆        ┆         ┆   ┆ 4ca538…       ┆ ac898382…    ┆            ┆             │\n",
       "│ 8    ┆ PDF      ┆ null   ┆ null    ┆ … ┆ a3de552a-f9ac ┆ 1965b41e-80e ┆ []         ┆ null        │\n",
       "│      ┆          ┆        ┆         ┆   ┆ -4358-81c5-ac ┆ 1-4ba7-a2cc- ┆            ┆             │\n",
       "│      ┆          ┆        ┆         ┆   ┆ 898382…       ┆ b5aa01cd…    ┆            ┆             │\n",
       "│ 8    ┆ PDF      ┆ null   ┆ null    ┆ … ┆ ddfd1e4c-48ae ┆ b63d4e93-40d ┆ []         ┆ null        │\n",
       "│      ┆          ┆        ┆         ┆   ┆ -44e6-abfa-1b ┆ b-42ed-ac90- ┆            ┆             │\n",
       "│      ┆          ┆        ┆         ┆   ┆ 9e986c…       ┆ 81f17e26…    ┆            ┆             │\n",
       "│ 8    ┆ PDF      ┆ null   ┆ null    ┆ … ┆ 1965b41e-80e1 ┆ f26c7a1f-7ba ┆ []         ┆ null        │\n",
       "│      ┆          ┆        ┆         ┆   ┆ -4ba7-a2cc-b5 ┆ b-4113-ac66- ┆            ┆             │\n",
       "│      ┆          ┆        ┆         ┆   ┆ aa01cd…       ┆ 960f1f72…    ┆            ┆             │\n",
       "│ 9    ┆ PDF      ┆ null   ┆ null    ┆ … ┆ f26c7a1f-7bab ┆ 634b20e4-f2d ┆ []         ┆ null        │\n",
       "│      ┆          ┆        ┆         ┆   ┆ -4113-ac66-96 ┆ 0-4d5e-aba5- ┆            ┆             │\n",
       "│      ┆          ┆        ┆         ┆   ┆ 0f1f72…       ┆ 808f4409…    ┆            ┆             │\n",
       "└──────┴──────────┴────────┴─────────┴───┴───────────────┴──────────────┴────────────┴─────────────┘"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide \n",
    "#| eval: false\n",
    "df_filtered = index.df.filter(\n",
    "    (pl.col(\"text\").str.contains(\"AI\", literal = False)) &\n",
    "    (pl.col(\"category\") == 'PDF') &\n",
    "    (pl.col(\"node_height\") == 0))\n",
    "df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide \n",
    "#| eval: false\n",
    "len(nodes[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
