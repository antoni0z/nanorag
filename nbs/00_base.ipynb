{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# base\n",
    "\n",
    "> Includes the main datastructures for Nodes and Documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from abc import ABC, abstractmethod\n",
    "from nbdev_rag.utils import *\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class BaseNode(ABC):\n",
    "    \"\"\"\n",
    "    Lowest level abstraction for storing interrelated pieces of information, building block for other types of nodes. \n",
    "    \"\"\"\n",
    "    def __init__(self, metadata, model_context, prev_node=None, next_node=None, parent_node=None, child_node=[], embedding=[]):\n",
    "        self.metadata = metadata\n",
    "        self.model_context = model_context\n",
    "        self.prev_node = prev_node  # In llama index they have relationships in one dict. I can try it.\n",
    "        self.next_node = next_node\n",
    "        self.parent_node = parent_node\n",
    "        self.child_node = child_node\n",
    "        self.embedding = embedding\n",
    "        self.id = self.__set_id()\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"BaseNode(id={self.id}, metadata={self.metadata}, prev_node={self.prev_node}, next_node={self.next_node}, parent_node={self.parent_node}, child_node={self.child_node})\"\n",
    "\n",
    "    def __set_id(self):\n",
    "        return uuid.uuid4()\n",
    "\n",
    "    def create_embedding(self):\n",
    "        # Create embedding with the specific content inside.\n",
    "        pass\n",
    "    @abstractmethod\n",
    "    def get_embedding(self):\n",
    "        # Return the embeddings stored\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class TextNode(BaseNode): #Add hash to verify content uniqueness\n",
    "    \"\"\"Class for creating chunks of Text that contain additional information like relationships of metadata, inheritance from\n",
    "    BaseNode but geared specifically towards text\"\"\"\n",
    "    def __init__(self, text, model_context, metadata, prev_node = None, next_node = None, parent_node = None, child_node = [], embedding = [], auto_embed = True):\n",
    "        super().__init__(metadata, model_context, prev_node, next_node, parent_node, child_node, embedding)\n",
    "        self.text = text\n",
    "        self.model_context = model_context\n",
    "        self.embedding = None\n",
    "        if auto_embed == True:\n",
    "            self.create_embedding()\n",
    "        self.hash = self.__calculate_hash()\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"TextNode(id = {self.id},text = {self.text},metadata = {self.metadata}, prev_node = {self.prev_node}, next_node = {self.next_node}, parent_node = {self.parent_node}, child_node = {self.child_node})\"\n",
    "    \n",
    "    def create_embedding(self):\n",
    "        if self.embedding == None:\n",
    "            self.embedding = self.model_context.embedding.encode([self.text], normalize_embeddings = True) #Huggingface sentence transformers. #TODO: Generalize this, create wrapper.Embedding model would have get and create embedding.\n",
    "    def get_embedding(self):\n",
    "        if self.embedding is None:\n",
    "            raise ValueError(\"embedding not set.\")\n",
    "        return self.embedding\n",
    "        #Embedding for text. Try one for image.\n",
    "\n",
    "    def __calculate_hash(self):\n",
    "        return hash_input(f\"{self.text}{self.metadata}{self.prev_node}{self.next_node}{self.parent_node}{self.child_node}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class Document(BaseNode): #A document is a collection of nodes #Add hash to verify content uniqueness\n",
    "    #Also can be the source of information.\n",
    "    \"\"\"\n",
    "    Class that serves as a way to group information that comes from different sources intended to be stored or integrated with other services\n",
    "    \"\"\"\n",
    "    def __init__(self, metadata = {}, name = None, text = None, prev_node = None, next_node = None, parent_node = None, child_node = [], embedding = []):\n",
    "        super().__init__(metadata, prev_node, next_node, parent_node, child_node, embedding)\n",
    "        self.nodes = []\n",
    "        self.text = text\n",
    "        self.name = name\n",
    "        self.hash = self.__calculate_hash()\n",
    "        #Maybe add some extra info like info_source that can help storing directly in db.\n",
    "        \n",
    "    def __call__(self, nodes):\n",
    "        self.nodes = nodes\n",
    "        self.hash = self.__calculate_hash()\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f\"Document(id = {self.id}, name = {self.name}, metadata = {self.metadata}, n_nodes = {len(self.nodes)})\"\n",
    "    \n",
    "    def __calculate_hash(self):\n",
    "        return hash_input(f\"{self.name}{self.metadata}{self.nodes}{self.prev_node}{self.next_node}{self.parent_node}{self.child_node}\")\n",
    "\n",
    "    def get_embedding(self):\n",
    "        #Return the embedding of the nodes\n",
    "        pass\n",
    "    \n",
    "    def create_nodes_from_doc(self,model_context, category = 'FILE', chunk_size = 1024):\n",
    "        nodes = []\n",
    "        chunked_text = self.__chunk_text(chunk_size)\n",
    "        existing_metadata = self.metadata\n",
    "        for i, text in enumerate(chunked_text):\n",
    "            if i == 0:\n",
    "                 prev_node = None\n",
    "                 next_node = None\n",
    "                 node_metadata = {**existing_metadata,**{'category' : category, 'node_height': 0, 'node_length':1}}\n",
    "                 nodes.append(TextNode(text = text, metadata = node_metadata, model_context = model_context))\n",
    "            else:\n",
    "                 node_metadata = {**existing_metadata,**{'category' : category, 'node_height': 0, 'node_length':1}}\n",
    "                 node = TextNode(text = text, metadata = node_metadata, model_context = model_context, prev_node =  nodes[i - 1].id)\n",
    "                 nodes.append(node)\n",
    "                 nodes[i - 1].next_node = node.id\n",
    "        return nodes\n",
    "        \n",
    "\n",
    "    def __chunk_text(self, chunk_size = 1024): #Make with other types of text representations like dataframes. Initial version.\n",
    "        chunked_text = []\n",
    "        text = self.text\n",
    "        for i in range(0, len(text), chunk_size):\n",
    "            chunked_text.append(text[i:chunk_size + i])\n",
    "        return chunked_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
