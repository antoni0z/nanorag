{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from nanorag.base import *\n",
    "from nanorag.store import *\n",
    "from nanorag.context import *\n",
    "from nanorag.llm import *\n",
    "from nanorag.loaders import *\n",
    "from typing import Union, List, Dict, Tuple, Optional, Any\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4f297e0afaa4a18a7fd26bec8e47d54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| export\n",
    "#| eval: false\n",
    "context = ModelContext()\n",
    "context.set_default()\n",
    "store = DocumentStore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For testing I would start exploring by having a document I want to be able to retrieve information from."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My naive implementation would be an index for the embedding and mapping with the node index. Lets try that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class VectorIndex: #Compatible with TextNode right now\n",
    "    def __init__(self, context): #May not be needed in postgres. \n",
    "        self.node_to_idx = {}\n",
    "        self.idx_to_node = {}\n",
    "        self.idx = np.array([], dtype=np.int64)\n",
    "        self.context = context\n",
    "        #This line below accepts huggingface embeddings format. \n",
    "        self.embedding_dim = self.context.embedding[1].word_embedding_dimension\n",
    "        if self.embedding_dim is not None:\n",
    "            self.embeddings = np.empty((0, self.embedding_dim))\n",
    "        else:\n",
    "            self.embeddings = np.array([])\n",
    "\n",
    "    def add(self, nodes: Union[TextNode, List[TextNode]]):\n",
    "        if isinstance(nodes, TextNode):\n",
    "            nodes = [nodes]\n",
    "        elif isinstance(nodes, list):\n",
    "            new_embeddings = np.vstack([node.embedding for node in nodes])\n",
    "            if self.embeddings.size == 0:\n",
    "                self.embeddings = new_embeddings\n",
    "            else:\n",
    "                self.embeddings = np.append(self.embeddings, new_embeddings, axis=0)\n",
    "            node_idx = np.arange(len(self.idx), self.embeddings.shape[0])\n",
    "            for node, idx in zip(nodes, node_idx):\n",
    "                self.node_to_idx[node.id] = idx\n",
    "                self.idx_to_node[idx] = node.id\n",
    "                node.idx = idx\n",
    "            self.idx = np.concatenate((self.idx, node_idx))\n",
    "\n",
    "    def get_embedding(self, ids: Union[List[int], int]):\n",
    "        if isinstance(ids, np.int64) or isinstance(ids, int):\n",
    "            ids = np.array([ids], dtype = np.int64)\n",
    "        if isinstance(ids, list):\n",
    "            ids = np.array(ids)\n",
    "        if isinstance(ids, np.ndarray):\n",
    "            return self.embeddings[ids]\n",
    "\n",
    "#TODO: Integration with the DocumentBridge and Document Object. \n",
    "#TODO: Try querying the Index with some text converted to embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| eval: false\n",
    "index = VectorIndex(context = context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| eval: false\n",
    "loader = PDFLoader('datasets/papers_pdf', store = store)\n",
    "documents = loader.get_documents()\n",
    "document = DocumentBridge(documents, context = context).to_doc()\n",
    "document.save()\n",
    "nodes = DocumentBridge(document, context = context).to_nodes()\n",
    "index.add(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59, 384)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "#| eval: false\n",
    "nodes_idxs = [node.idx for node in nodes]\n",
    "index.get_embedding(nodes_idxs).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(124, 384)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "#| eval: false\n",
    "index.embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| eval: false\n",
    "loader = PDFLoader('datasets/papers_pdf', store = store)\n",
    "documents = loader.get_documents()\n",
    "document = DocumentBridge(documents, context = context).to_doc()\n",
    "document.save()\n",
    "nodes = DocumentBridge(document, context = context).to_nodes()\n",
    "index.add(nodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
