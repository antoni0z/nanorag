{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indexing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from nanorag.base import *\n",
    "from nanorag.store import *\n",
    "from nanorag.context import *\n",
    "from nanorag.llm import *\n",
    "from nanorag.loaders import *\n",
    "from typing import Union, List, Dict, Tuple, Optional, Any\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5da1e4fca7a4464bac623743feb57a4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| export\n",
    "#| eval: false\n",
    "context = ModelContext()\n",
    "context.set_default()\n",
    "store = DocumentStore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For testing I would start exploring by having a document I want to be able to retrieve information from."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My naive implementation would be an index for the embedding and mapping with the node index. Lets try that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "#| export\n",
    "class VectorNodesIndex: #Compatible with TextNode right now. Storage of reference of certain nodes.\n",
    "    #Have a store that has the nodes corresponding to certain ids.Ex Node Store. \n",
    "    #Question. Treat docstore the\n",
    "    def __init__(self, context): #May not be needed in postgres. \n",
    "        self.idx_to_node = {}\n",
    "        self.idx = np.array([], dtype=np.int64)\n",
    "        self.context = context\n",
    "        #This line below accepts huggingface embeddings format. \n",
    "        self.embedding_dim = self.context.embedding[1].word_embedding_dimension\n",
    "        if self.embedding_dim is not None:\n",
    "            self.embeddings = np.empty((0, self.embedding_dim))\n",
    "        else:\n",
    "            self.embeddings = np.array([])\n",
    "\n",
    "    def add(self, nodes: Union[TextNode, List[TextNode]]): #Embed with non excluded content. \n",
    "        if isinstance(nodes, TextNode):\n",
    "            nodes = [nodes]\n",
    "        elif isinstance(nodes, list):\n",
    "            new_embeddings = np.vstack([node.embedding for node in nodes])\n",
    "            if self.embeddings.size == 0:\n",
    "                self.embeddings = new_embeddings\n",
    "            else:\n",
    "                self.embeddings = np.append(self.embeddings, new_embeddings, axis=0)\n",
    "            node_idx = np.arange(len(self.idx), self.embeddings.shape[0])\n",
    "            for node, idx in zip(nodes, node_idx):\n",
    "                self.idx_to_node[idx] = node.id\n",
    "                node.idx_ref = idx\n",
    "            self.idx = np.concatenate((self.idx, node_idx))\n",
    "\n",
    "    def get_nodes(self, idx_refs: List[int]):\n",
    "        \"\"\"Providing a list of idx_refs of the nodes, get the corresponding node ids\"\"\"\n",
    "        return [self.idx_to_node[idx_ref] for idx_ref in idx_refs]\n",
    "\n",
    "    def get_embedding(self, idx_ref: Union[List[int], int]):\n",
    "        \"\"\"Providing the idx_ref of the node, or nodes get the embedding\"\"\"\n",
    "        if isinstance(idx_ref, np.int64) or isinstance(idx_ref, int):\n",
    "            idx_ref = np.array([idx_ref], dtype = np.int64)\n",
    "        if isinstance(idx_ref, list):\n",
    "            idx_ref = np.array(idx_ref, dtype= np.int64)\n",
    "        if isinstance(idx_ref, np.ndarray):\n",
    "            return self.embeddings[idx_ref]\n",
    "\n",
    "    def query(self, query_str: List[str], top_k: int = 10):\n",
    "        \"\"\"Query the index with a list of strings. Returns the top_k results.\"\"\"\n",
    "        query_embedding = self.context.embedding.encode(query_str)\n",
    "        similarity = cosine_similarity(query_embedding, self.embeddings)\n",
    "        distance = 1 - similarity  # Compute cosine distance as a score\n",
    "        topk_idx = np.argsort(distance).flatten()\n",
    "        topk_idx_ref = self.idx[topk_idx][:top_k]\n",
    "        nodes = self.get_nodes(topk_idx_ref)\n",
    "        return nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| eval: false\n",
    "index = VectorNodesIndex(context)\n",
    "loader = PDFLoader('datasets/papers_pdf', store = store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "# | eval: false\n",
    "\n",
    "documents = loader.get_documents()\n",
    "document = DocumentBridge(documents, context = context).to_doc()\n",
    "nodes = DocumentBridge(document, context = context).to_nodes()\n",
    "document.save()\n",
    "store.add(nodes)\n",
    "index.add(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "# | eval: false\n",
    "\n",
    "#Get source. \n",
    "idx_node_list = index.query(['End to end'], top_k = 3)\n",
    "doc_id = [doc.doc_id for doc in store.get(idx_node_list)]\n",
    "store.get(doc_id)[0].text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
