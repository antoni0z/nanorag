{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8404bfc-069b-49b4-b140-49c850418b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fc954c-662d-4ac0-96f2-84bcb70a8950",
   "metadata": {},
   "source": [
    "# Loaders\n",
    "\n",
    "> A module for importing data and converting it to a processable output for the most typical file formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aef0a0e-b785-4395-8f52-8c42e9998aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import PyPDF2\n",
    "from pathlib import Path\n",
    "from PyPDF2 import PdfReader\n",
    "import random\n",
    "from typing import List\n",
    "import uuid\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee48c660-a2f3-4984-b1ec-43f15d7d2666",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from nanorag.store import *\n",
    "from nanorag.base import *\n",
    "from nanorag.context import *\n",
    "from nanorag.llm import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b945c117-c52c-4816-822b-235d32a89caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f679303-536a-42ac-a5a0-e62315cbaccc",
   "metadata": {},
   "source": [
    "#|hide\n",
    "We have a set of PDF files we previously downloaded to test out and create a PDF loader. We will try to create a loader that extract both images and text in an structured way. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8099616f-6a84-4c8c-ac35-09f4df9cbf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#For simplicity lets start with accepting a List. \n",
    "class PDFLoader:\n",
    "    \"\"\"Accepts a dir or single path and converts its contents into documents that can be later used for storage and retrieval\"\"\"\n",
    "    def __init__(self, path_dir: str):\n",
    "        self.path_dir = Path(path_dir)\n",
    "        if self.path_dir.is_dir():\n",
    "            self.paths = [path for path in self.path_dir.iterdir() if path]\n",
    "        else:\n",
    "            self.paths = [self.path_dir]\n",
    "        self.path = None\n",
    "        \n",
    "    def pdf_validator(self, path):\n",
    "        \"\"\"Tries to read the pdf and returns a Bool value with the result\"\"\"\n",
    "        try:\n",
    "            reader = PdfReader(path)\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            return False\n",
    "\n",
    "    def load_random_pdf(self):\n",
    "        \"\"\"Load a random pdf from the dataset. It loads pdfs until a valid one is found\"\"\"\n",
    "        valid_pdf_found = False\n",
    "        while not valid_pdf_found:  # Continue until a valid PDF is found\n",
    "            pdf_path = random.choice(self.paths)\n",
    "            is_valid = self.pdf_validator(pdf_path)\n",
    "            if is_valid:\n",
    "                reader = PdfReader(pdf_path)\n",
    "                valid_pdf_found = True\n",
    "                self.path = pdf_path\n",
    "                return reader\n",
    "            else:\n",
    "                pdf_path.unlink()\n",
    "                self.paths.remove(pdf_path)  # Remove the invalid path from the list\n",
    "        \n",
    "        if not valid_pdf_found:\n",
    "            return None\n",
    "    def load_pdf(self, path):\n",
    "        reader = PdfReader(path)\n",
    "        self.path = path\n",
    "        return reader\n",
    "    \n",
    "    def get_documents(self, path = None):\n",
    "        \"\"\"Get a List of Text Documents from a pdf Path.\"\"\"\n",
    "        documents = []\n",
    "        #Extracting text and storing it in documents\n",
    "        if path == None:\n",
    "            reader = self.load_random_pdf()\n",
    "        else:\n",
    "            reader = self.load_pdf(path)\n",
    "        for i, page in enumerate(reader.pages):\n",
    "            params = {\"metadata\": {**{\"page\": i + 1}, **reader.metadata}, \"text\": page.extract_text()}\n",
    "            if i == 0:\n",
    "                title = reader.metadata.get('title', None)\n",
    "                if title is None:\n",
    "                    title = params['text'].split('\\n')[0]        \n",
    "            if title is not None:\n",
    "                params[\"name\"] = title\n",
    "            doc = Document(**params)\n",
    "            documents.append(doc)\n",
    "        return documents\n",
    "    def get_images(self, path = None):\n",
    "        #Can add some metadata like what page and location was found on. \n",
    "        #Create Image Node with that kind of info. \n",
    "        if path == None:\n",
    "            reader = self.load_random_pdf()\n",
    "        else:\n",
    "            reader = self.load_pdf(path)\n",
    "        images = []\n",
    "        for count, page in enumerate(reader.pages):\n",
    "            for image_file_object in page.images:\n",
    "                image = Image.open(BytesIO(image_file_object.data))\n",
    "                images.append(image)\n",
    "        return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f068f724-47ea-4192-9986-d340776d8c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class DocumentBridge:\n",
    "    \"\"\"Class for connecting a list of documents into its corresponding Nodes and relationships\"\"\"\n",
    "    def __init__(self, documents: List, context: ModelContext):\n",
    "        if isinstance(documents, List):\n",
    "            self.documents = documents\n",
    "        else:\n",
    "            raise \"You have to include a List of documents\"\n",
    "        self.context = context\n",
    "    def nodes(self, chunk_size = 1024) -> List[TextNode]:\n",
    "        \"\"\"Brige a series of Documents into nodes linked by the end and start of the prev and next document. Great for linking together complex docs with structure\n",
    "        such as pages or other info extracted first on a Document basis.\"\"\"\n",
    "        doc_nodes_list = [doc.create_nodes_from_doc(model_context = self.context, chunk_size = chunk_size) for doc in self.documents]\n",
    "        for i, node_list in enumerate(doc_nodes_list):\n",
    "            if i == 0:\n",
    "                node_list[-1].next_node = doc_nodes_list[i + 1][0].id\n",
    "            else:\n",
    "                if i < len(doc_nodes_list) - 1:\n",
    "                    node_list[-1].next_node = doc_nodes_list[i + 1][0].id\n",
    "                node_list[0].prev_node = doc_nodes_list[i - 1][-1].id\n",
    "        nodes = [node for node_list in doc_nodes_list for node in node_list]\n",
    "        return nodes\n",
    "        \n",
    "    def join(self) -> Document:\n",
    "        \"\"\"Bridges a series of Documents into a single document. Great for storing sub-documents into a single one. Keeps some metadata of the documents into one. \"\"\"\n",
    "        #Store metadata about length, pages etc. For the later processing to be better. Maybe metadata about where each page started and ended in terms of characters could be good. \n",
    "        #see tradeoffs between this and diff docs pointing to a single reference. \n",
    "        #In reality in the conversion to nodes all the info is kept. We can post-process there. \n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9448a0f8-8817-4b41-9d1e-13e7f57d1c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#|eval: false\n",
    "context = ModelContext()\n",
    "context.set_default()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b246bb-f801-412d-96d3-54d06dcf39b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|eval: false\n",
    "loader = PDFLoader('datasets/papers_pdf')\n",
    "documents = loader.get_documents()\n",
    "images = loader.get_images(path = loader.path)\n",
    "bridge = DocumentBridge(documents, context = context)\n",
    "nodes = bridge.nodes(chunk_size = 2500)\n",
    "nodes[:1]\n",
    "#For images save surrounding image context for context + gpt/blip interpretation of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d399ffa9-9d01-4ce6-b19e-2f4120e3eeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|eval: false\n",
    "store = DocumentStore(documents)\n",
    "ids = store.ids()\n",
    "store.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cdd428-3ac7-4ba4-9284-b263f98054e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|eval: false\n",
    "# Maybe I can make it so the bridge knows if an object is a Node or a Doc when inputting it and serves for both. \n",
    "documents = store.get()\n",
    "bridge = DocumentBridge(documents, context = context)\n",
    "nodes = bridge.nodes()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2411c4-df1a-4a5b-8259-6666f6ef15cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cfe06c-ab4c-45d2-a68c-2aa5cca8896b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a4a378-177c-43b0-8b05-ed573ec0f410",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba3c177-be06-47fd-ac69-d2ce2c3efd36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
