{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8404bfc-069b-49b4-b140-49c850418b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fc954c-662d-4ac0-96f2-84bcb70a8950",
   "metadata": {},
   "source": [
    "# Loaders\n",
    "\n",
    "> A module for importing data and converting it to a processable output for the most typical file formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aef0a0e-b785-4395-8f52-8c42e9998aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import PyPDF2\n",
    "from pathlib import Path\n",
    "from PyPDF2 import PdfReader\n",
    "import random\n",
    "from typing import List\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee48c660-a2f3-4984-b1ec-43f15d7d2666",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev_rag.store import *\n",
    "from nbdev_rag.base import *\n",
    "from nbdev_rag.context import *\n",
    "from nbdev_rag.llm import *\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f679303-536a-42ac-a5a0-e62315cbaccc",
   "metadata": {},
   "source": [
    "#|hide\n",
    "We have a set of PDF files we previously downloaded to test out and create a PDF loader. We will try to create a loader that extract both images and text in an structured way. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8099616f-6a84-4c8c-ac35-09f4df9cbf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#For simplicity lets start with accepting a List. \n",
    "class PDFLoader:\n",
    "    \"\"\"Accepts a dir or single path and converts its contents into documents that can be later used for storage and retrieval\"\"\"\n",
    "    def __init__(self, path_dir: str):\n",
    "        self.path_dir = Path(path_dir)\n",
    "        if self.path_dir.is_dir():\n",
    "            self.paths = [path for path in self.path_dir.iterdir() if path]\n",
    "        else:\n",
    "            self.paths = [self.path_dir]\n",
    "    \n",
    "    def pdf_validator(self, path):\n",
    "        \"\"\"Tries to read the pdf and returns a Bool value with the result\"\"\"\n",
    "        try:\n",
    "            reader = PdfReader(path)\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            return False\n",
    "\n",
    "    def load_random_pdf(self):\n",
    "        \"\"\"Load a random pdf from the dataset. It loads pdfs until a valid one is found\"\"\"\n",
    "        valid_pdf_found = False\n",
    "        while not valid_pdf_found:  # Continue until a valid PDF is found\n",
    "            pdf_path = random.choice(self.paths)\n",
    "            is_valid = self.pdf_validator(pdf_path)\n",
    "            if is_valid:\n",
    "                reader = PdfReader(pdf_path)\n",
    "                valid_pdf_found = True\n",
    "                return reader\n",
    "            else:\n",
    "                pdf_path.unlink()\n",
    "                self.paths.remove(pdf_path)  # Remove the invalid path from the list\n",
    "    \n",
    "        if not valid_pdf_found:\n",
    "            return None\n",
    "    def load_pdf(self, path):\n",
    "        reader = PdfReader(path)\n",
    "        return reader\n",
    "    \n",
    "    def get_documents(self, path = None):\n",
    "        \"\"\"Get a List of Text Documents from a pdf Path.\"\"\"\n",
    "        documents = []\n",
    "        #Extracting text and storing it in documents\n",
    "        if path == None:\n",
    "            reader = self.load_random_pdf()\n",
    "        else:\n",
    "            reader = self.load_pdf(path)\n",
    "        for i, page in enumerate(reader.pages):\n",
    "            params = {\"metadata\": {**{\"page\": i + 1}, **reader.metadata}, \"text\": page.extract_text()}\n",
    "            if i == 0:\n",
    "                title = reader.metadata.get('title', None)\n",
    "                if title is None:\n",
    "                    title = params['text'].split('\\n')[0]        \n",
    "            if title is not None:\n",
    "                params[\"name\"] = title\n",
    "            doc = Document(**params)\n",
    "            documents.append(doc)\n",
    "        return documents\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f068f724-47ea-4192-9986-d340776d8c23",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'List' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#| export\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mDocumentBridge\u001b[39;00m:\n\u001b[1;32m      3\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Class for connecting a list of documents into its corresponding Nodes and relationships\"\"\"\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, documents: List, context: ModelContext):\n",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m, in \u001b[0;36mDocumentBridge\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mDocumentBridge\u001b[39;00m:\n\u001b[1;32m      3\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Class for connecting a list of documents into its corresponding Nodes and relationships\"\"\"\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, documents: \u001b[43mList\u001b[49m, context: ModelContext):\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(documents, List):\n\u001b[1;32m      6\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdocuments \u001b[38;5;241m=\u001b[39m documents\n",
      "\u001b[0;31mNameError\u001b[0m: name 'List' is not defined"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "class DocumentBridge:\n",
    "    \"\"\"Class for connecting a list of documents into its corresponding Nodes and relationships\"\"\"\n",
    "    def __init__(self, documents: List, context: ModelContext):\n",
    "        if isinstance(documents, List):\n",
    "            self.documents = documents\n",
    "        else:\n",
    "            raise \"You have to include a List of documents\"\n",
    "        self.context = context\n",
    "    def nodes(self) -> List[TextNode]:\n",
    "        \"\"\"Brige a series of Documents into nodes linked by the end and start of the prev and next document. Great for linking together complex docs with structure\n",
    "        such as pages or other info extracted first on a Document basis.\"\"\"\n",
    "        doc_nodes_list = [doc.create_nodes_from_doc(self.context) for doc in self.documents]\n",
    "        for i, node_list in enumerate(doc_nodes_list):\n",
    "            if i == 0:\n",
    "                node_list[-1].next_node = doc_nodes_list[i + 1][0].id\n",
    "            else:\n",
    "                if i < len(doc_nodes_list) - 1:\n",
    "                    node_list[-1].next_node = doc_nodes_list[i + 1][0].id\n",
    "                node_list[0].prev_node = doc_nodes_list[i - 1][-1].id\n",
    "        nodes = [node for node_list in doc_nodes_list for node in node_list]\n",
    "        return nodes\n",
    "    def document(self) -> List[Document]:\n",
    "        \"\"\"Bridges a series of Documents into a single document. Great for storing sub-documents into a single one. Keeps some metadata of the documents into one. \"\"\"\n",
    "        #Store metadata about length, pages etc. For the later processing to be better. Maybe metadata about where each page started and ended in terms of characters could be good. \n",
    "        #see tradeoffs between this and diff docs pointing to a single reference. \n",
    "        #In reality in the conversion to nodes all the info is kept. We can post-process there. \n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9448a0f8-8817-4b41-9d1e-13e7f57d1c33",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AutoTokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#| hide\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mAutoTokenizer\u001b[49m\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmistralai/Mistral-7B-Instruct-v0.2\u001b[39m\u001b[38;5;124m\"\u001b[39m, device_map \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m AutoModelForCausalLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmistralai/Mistral-7B-Instruct-v0.2\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m     device_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m     torch_dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mbfloat16,\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      8\u001b[0m embedding_model \u001b[38;5;241m=\u001b[39m SentenceTransformer(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentence-transformers/all-MiniLM-L6-v2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'AutoTokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\", device_map = \"cuda\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "    device_map=\"cuda\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "embedding_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "llm = LLM(model = model, tokenizer = tokenizer)\n",
    "context = ModelContext(llm = llm, embedding = embedding_model, tokenizer = tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b246bb-f801-412d-96d3-54d06dcf39b5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#|hide\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m loader \u001b[38;5;241m=\u001b[39m \u001b[43mPDFLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdatasets/papers_pdf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m documents \u001b[38;5;241m=\u001b[39m loader\u001b[38;5;241m.\u001b[39mget_documents()\n\u001b[1;32m      4\u001b[0m bridge \u001b[38;5;241m=\u001b[39m DocumentBridge(documents, context \u001b[38;5;241m=\u001b[39m context)\n",
      "Cell \u001b[0;32mIn[1], line 6\u001b[0m, in \u001b[0;36mPDFLoader.__init__\u001b[0;34m(self, path_dir)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, path_dir: \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m----> 6\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath_dir \u001b[38;5;241m=\u001b[39m \u001b[43mPath\u001b[49m(path_dir)\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath_dir\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpaths \u001b[38;5;241m=\u001b[39m [path \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath_dir\u001b[38;5;241m.\u001b[39miterdir() \u001b[38;5;28;01mif\u001b[39;00m path]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Path' is not defined"
     ]
    }
   ],
   "source": [
    "#|hide\n",
    "loader = PDFLoader('datasets/papers_pdf')\n",
    "documents = loader.get_documents()\n",
    "bridge = DocumentBridge(documents, context = context)\n",
    "nodes = bridge.nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f536b0b-0da7-44c0-b546-04ddb52f1ab8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nodes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#|hide\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mnodes\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nodes' is not defined"
     ]
    }
   ],
   "source": [
    "#|hide\n",
    "nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2411c4-df1a-4a5b-8259-6666f6ef15cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f46c1a-060e-4a3a-b761-12f53c733bea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cfe06c-ab4c-45d2-a68c-2aa5cca8896b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a4a378-177c-43b0-8b05-ed573ec0f410",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba3c177-be06-47fd-ac69-d2ce2c3efd36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
