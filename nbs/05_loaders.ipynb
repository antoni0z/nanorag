{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8404bfc-069b-49b4-b140-49c850418b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fc954c-662d-4ac0-96f2-84bcb70a8950",
   "metadata": {},
   "source": [
    "# Loaders\n",
    "\n",
    "> A module for importing data and converting it to a processable output for the most typical file formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aef0a0e-b785-4395-8f52-8c42e9998aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import PyPDF2\n",
    "from pathlib import Path\n",
    "from PyPDF2 import PdfReader\n",
    "import random\n",
    "from typing import List\n",
    "import uuid\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee48c660-a2f3-4984-b1ec-43f15d7d2666",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nanorag.store import *\n",
    "from nanorag.base import *\n",
    "from nanorag.context import *\n",
    "from nanorag.llm import *\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f679303-536a-42ac-a5a0-e62315cbaccc",
   "metadata": {},
   "source": [
    "#|hide\n",
    "We have a set of PDF files we previously downloaded to test out and create a PDF loader. We will try to create a loader that extract both images and text in an structured way. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8099616f-6a84-4c8c-ac35-09f4df9cbf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#For simplicity lets start with accepting a List. \n",
    "class PDFLoader:\n",
    "    \"\"\"Accepts a dir or single path and converts its contents into documents that can be later used for storage and retrieval\"\"\"\n",
    "    def __init__(self, path_dir: str):\n",
    "        self.path_dir = Path(path_dir)\n",
    "        if self.path_dir.is_dir():\n",
    "            self.paths = [path for path in self.path_dir.iterdir() if path]\n",
    "        else:\n",
    "            self.paths = [self.path_dir]\n",
    "        self.path = None\n",
    "        \n",
    "    def pdf_validator(self, path):\n",
    "        \"\"\"Tries to read the pdf and returns a Bool value with the result\"\"\"\n",
    "        try:\n",
    "            reader = PdfReader(path)\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            return False\n",
    "\n",
    "    def load_random_pdf(self):\n",
    "        \"\"\"Load a random pdf from the dataset. It loads pdfs until a valid one is found\"\"\"\n",
    "        valid_pdf_found = False\n",
    "        while not valid_pdf_found:  # Continue until a valid PDF is found\n",
    "            pdf_path = random.choice(self.paths)\n",
    "            is_valid = self.pdf_validator(pdf_path)\n",
    "            if is_valid:\n",
    "                reader = PdfReader(pdf_path)\n",
    "                valid_pdf_found = True\n",
    "                self.path = pdf_path\n",
    "                return reader\n",
    "            else:\n",
    "                pdf_path.unlink()\n",
    "                self.paths.remove(pdf_path)  # Remove the invalid path from the list\n",
    "        \n",
    "        if not valid_pdf_found:\n",
    "            return None\n",
    "    def load_pdf(self, path):\n",
    "        reader = PdfReader(path)\n",
    "        self.path = path\n",
    "        return reader\n",
    "    \n",
    "    def get_documents(self, path = None):\n",
    "        \"\"\"Get a List of Text Documents from a pdf Path.\"\"\"\n",
    "        documents = []\n",
    "        #Extracting text and storing it in documents\n",
    "        if path == None:\n",
    "            reader = self.load_random_pdf()\n",
    "        else:\n",
    "            reader = self.load_pdf(path)\n",
    "        for i, page in enumerate(reader.pages):\n",
    "            params = {\"metadata\": {**{\"page\": i + 1}, **reader.metadata}, \"text\": page.extract_text()}\n",
    "            if i == 0:\n",
    "                title = reader.metadata.get('title', None)\n",
    "                if title is None:\n",
    "                    title = params['text'].split('\\n')[0]        \n",
    "            if title is not None:\n",
    "                params[\"name\"] = title\n",
    "            doc = Document(**params)\n",
    "            documents.append(doc)\n",
    "        return documents\n",
    "    def get_images(self, path = None):\n",
    "        #Can add some metadata like what page and location was found on. \n",
    "        #Create Image Node with that kind of info. \n",
    "        if path == None:\n",
    "            reader = self.load_random_pdf()\n",
    "        else:\n",
    "            reader = self.load_pdf(path)\n",
    "        images = []\n",
    "        for count, page in enumerate(reader.pages):\n",
    "            for image_file_object in page.images:\n",
    "                image = Image.open(BytesIO(image_file_object.data))\n",
    "                images.append(image)\n",
    "        return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f068f724-47ea-4192-9986-d340776d8c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class DocumentBridge:\n",
    "    \"\"\"Class for connecting a list of documents into its corresponding Nodes and relationships\"\"\"\n",
    "    def __init__(self, documents: List, context: ModelContext):\n",
    "        if isinstance(documents, List):\n",
    "            self.documents = documents\n",
    "        else:\n",
    "            raise \"You have to include a List of documents\"\n",
    "        self.context = context\n",
    "    def nodes(self, chunk_size = 1024) -> List[TextNode]:\n",
    "        \"\"\"Brige a series of Documents into nodes linked by the end and start of the prev and next document. Great for linking together complex docs with structure\n",
    "        such as pages or other info extracted first on a Document basis.\"\"\"\n",
    "        doc_nodes_list = [doc.create_nodes_from_doc(self.context, chunk_size = chunk_size) for doc in self.documents]\n",
    "        for i, node_list in enumerate(doc_nodes_list):\n",
    "            if i == 0:\n",
    "                node_list[-1].next_node = doc_nodes_list[i + 1][0].id\n",
    "            else:\n",
    "                if i < len(doc_nodes_list) - 1:\n",
    "                    node_list[-1].next_node = doc_nodes_list[i + 1][0].id\n",
    "                node_list[0].prev_node = doc_nodes_list[i - 1][-1].id\n",
    "        nodes = [node for node_list in doc_nodes_list for node in node_list]\n",
    "        return nodes\n",
    "        \n",
    "    def join(self) -> Document:\n",
    "        \"\"\"Bridges a series of Documents into a single document. Great for storing sub-documents into a single one. Keeps some metadata of the documents into one. \"\"\"\n",
    "        #Store metadata about length, pages etc. For the later processing to be better. Maybe metadata about where each page started and ended in terms of characters could be good. \n",
    "        #see tradeoffs between this and diff docs pointing to a single reference. \n",
    "        #In reality in the conversion to nodes all the info is kept. We can post-process there. \n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9448a0f8-8817-4b41-9d1e-13e7f57d1c33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5135ed5bf8f47108e51e945b363391b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| hide\n",
    "#|eval: false\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\", device_map = \"cuda\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "    device_map=\"cuda\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "embedding_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "llm = LLM(model = model, tokenizer = tokenizer)\n",
    "context = ModelContext(llm = llm, embedding = embedding_model, tokenizer = tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b246bb-f801-412d-96d3-54d06dcf39b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TextNode(id = e4f95fec-3b77-4fea-a7dc-99e2de121b60,text = Time Series Classiﬁcation from Scratch with Deep\n",
       " Neural Networks: A Strong Baseline\n",
       " Zhiguang Wang, Weizhong Yan\n",
       " GE Global Research\n",
       " fzhiguang.wang, yan g@ge.comTim Oates\n",
       " Computer Science and Electric Engineering\n",
       " University of Maryland Baltimore County\n",
       " oates@umbc.edu\n",
       " Abstract —We propose a simple but strong baseline for time\n",
       " series classiﬁcation from scratch with deep neural networks. Our\n",
       " proposed baseline models are pure end-to-end without any heavy\n",
       " preprocessing on the raw data or feature crafting. The proposed\n",
       " Fully Convolutional Network (FCN) achieves premium perfor-\n",
       " mance to other state-of-the-art approaches and our exploration\n",
       " of the very deep neural networks with the ResNet structure is\n",
       " also competitive. The global average pooling in our convolutional\n",
       " model enables the exploitation of the Class Activation Map\n",
       " (CAM) to ﬁnd out the contributing region in the raw data for\n",
       " the speciﬁc labels. Our models provides a simple choice for\n",
       " the real world application and a good starting point for the\n",
       " future research. An overall analysis is provided to discuss the\n",
       " generalization capability of our models, learned features, network\n",
       " structures and the classiﬁcation semantics.\n",
       " I. I NTRODUCTION\n",
       " Time series data is ubiquitous. Both human activities and\n",
       " nature produces time series everyday and everywhere, like\n",
       " weather readings, ﬁnancial recordings, physiological signals\n",
       " and industrial observations. As the simplest type of time series\n",
       " data, univariate time series provides a reasonably good start-\n",
       " ing point to study such temporal signals. The representation\n",
       " learning and classiﬁcation research has found many potential\n",
       " application in the ﬁelds like ﬁnance, industry, and health care.\n",
       " However, learning representations and classifying time se-\n",
       " ries are still attracting much attention. As the earliest baseline,\n",
       " distance-based methods work directly on raw time series\n",
       " with some pre-deﬁned similarity measures such as Euclidean\n",
       " distance or Dynamic time warping (DTW) [1] to perform\n",
       " classiﬁcation. The combination of DTW and the k-nearest-\n",
       " neighbors classiﬁer is known to be a very efﬁcient approach\n",
       " as a golden standard in the last decade.\n",
       " Feature-based methods suppose to extract a set of features\n",
       " that are able to represent the global/local time series patterns.\n",
       " Commonly, these features are quantized to form a Bag-of-\n",
       " Words (BoW), then given to the classiﬁers [2]. Feature-based\n",
       " approaches mostly differ in the extracted features. To name\n",
       " a few recent benchmarks, The bag-of-features framew,metadata = {'page': 1, '/Author': '', '/CreationDate': 'D:20161215013614Z', '/Creator': 'LaTeX with hyperref package', '/Keywords': '', '/ModDate': 'D:20161215013614Z', '/PTEX.Fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', '/Producer': 'pdfTeX-1.40.12', '/Subject': '', '/Title': '', '/Trapped': '/False', 'category': 'FILE', 'node_height': 0, 'node_length': 1}, prev_node = None, next_node = 52f88e11-c561-4461-9a41-ebe8e747d689, parent_node = None, child_node = []),\n",
       " TextNode(id = 52f88e11-c561-4461-9a41-ebe8e747d689,text = ork\n",
       " (TSBF) [3] extracts the interval features with different scales\n",
       " from each interval to form an instance, and each time series\n",
       " forms a bag. A supervised codebook is built with the random\n",
       " forest for classifying the time series. Bag-of-SFA-Symbols\n",
       " (BOSS) [4] proposes a distance based on the histograms\n",
       " of symbolic Fourier approximation words. Its extension, the\n",
       " BOSSVS method [5] combines the BOSS model with thevector space model to reduce the time complexity and improve\n",
       " the performance by ensembling the models with difference\n",
       " window size. The ﬁnal classiﬁcation is performed with the\n",
       " One-Nearest-Neighbor classiﬁer.\n",
       " Ensemble based approaches combine different classiﬁers\n",
       " together to achieve a higher accuracy. Different ensemble\n",
       " paradigms integrate various feature sets or classiﬁers. The\n",
       " Elastic Ensemble (PROP) [6] combines 11 classiﬁers based on\n",
       " elastic distance measures with a weighted ensemble scheme.\n",
       " Shapelet ensemble (SE) [7] produces the classiﬁers through\n",
       " the shapelet transform in conjunction with a heterogeneous\n",
       " ensemble. The ﬂat collective of transform-based ensembles\n",
       " (COTE) is an ensemble of 35 different classiﬁers based on the\n",
       " features extracted from both the time and frequency domains.\n",
       " All the above approaches need heavy crafting on data\n",
       " preprocessing and feature engineering. Recently, some effort\n",
       " has been spent to exploit the deep neural network, especially\n",
       " convolutional neural networks (CNN) for end-to-end time\n",
       " series classiﬁcation. In [8], a multi-channel CNN (MC-CNN)\n",
       " is proposed for multivariate time series classiﬁcation. The\n",
       " ﬁlters are applied on each single channel and the features are\n",
       " ﬂattened across channels as the input to a fully connected\n",
       " layer. The authors applied sliding windows to enhance the\n",
       " data. They only evaluate this approach on two multivariate\n",
       " time series datasets, where there is no published benchmark\n",
       " for comparison. In [9], the author proposed a multi-scale CNN\n",
       " approach (MCNN) for univariate time series classiﬁcation.\n",
       " Down sampling, skip sampling and sliding windows are used\n",
       " for preprocessing the data to manually prepare for the multi-\n",
       " scale settings. Although this approach claims the state-of-the-\n",
       " art performance on 44 UCR time series datasets [10], the heavy\n",
       " preprocessing efforts and a large set of hyperparameters make\n",
       " it complicated to deploy. The proposed window slicing method\n",
       " for data augmentation seems to be ad-hoc.\n",
       " We provide a standard baseline to exploit deep neural\n",
       " networks for end-to-end time series classiﬁcation wi,metadata = {'page': 1, '/Author': '', '/CreationDate': 'D:20161215013614Z', '/Creator': 'LaTeX with hyperref package', '/Keywords': '', '/ModDate': 'D:20161215013614Z', '/PTEX.Fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', '/Producer': 'pdfTeX-1.40.12', '/Subject': '', '/Title': '', '/Trapped': '/False', 'category': 'FILE', 'node_height': 0, 'node_length': 1}, prev_node = e4f95fec-3b77-4fea-a7dc-99e2de121b60, next_node = 4da3af91-c4ae-4ef6-bcb9-46d9e75ae0a9, parent_node = None, child_node = []),\n",
       " TextNode(id = 4da3af91-c4ae-4ef6-bcb9-46d9e75ae0a9,text = thout any\n",
       " crafting in feature engineering and data preprocessing. The\n",
       " deep multilayer perceptrons (MLP), fully convolutional net-\n",
       " works (FCN) and the residual networks (ResNet) are evaluated\n",
       " on the same 44 benchmark datasets with other benchmarks.\n",
       " Through a pure end-to-end training on the raw time series\n",
       " data , the ResNet and FCN achieve comparable or better\n",
       " performance than COTE and MCNN. The global average\n",
       " pooling in our convolutional model enables the exploitation ofarXiv:1611.06455v4  [cs.LG]  14 Dec 2016,metadata = {'page': 1, '/Author': '', '/CreationDate': 'D:20161215013614Z', '/Creator': 'LaTeX with hyperref package', '/Keywords': '', '/ModDate': 'D:20161215013614Z', '/PTEX.Fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', '/Producer': 'pdfTeX-1.40.12', '/Subject': '', '/Title': '', '/Trapped': '/False', 'category': 'FILE', 'node_height': 0, 'node_length': 1}, prev_node = 52f88e11-c561-4461-9a41-ebe8e747d689, next_node = 2777e78e-dfe1-4344-a931-cdc857f60b71, parent_node = None, child_node = []),\n",
       " TextNode(id = 2777e78e-dfe1-4344-a931-cdc857f60b71,text = 500Input\n",
       " 500\n",
       " 500\n",
       " SoftmaxInput\n",
       " Softmax0.1 0.2 0.2 0.3ReLU\n",
       " ReLU\n",
       " ReLU\n",
       " 128\n",
       " BN + ReLU\n",
       " 256\n",
       " BN + ReLU\n",
       " 128\n",
       " BN + ReLUInput\n",
       " 64\n",
       " BN + ReLU\n",
       " 64\n",
       " BN + ReLU\n",
       " 64\n",
       " BN + ReLU\n",
       " Global Pooling\n",
       " 128\n",
       " BN + ReLU\n",
       " 128\n",
       " BN + ReLU\n",
       " 128\n",
       " BN + ReLU\n",
       " 128\n",
       " BN + ReLU\n",
       " 128\n",
       " BN + ReLU\n",
       " 128\n",
       " BN + ReLU\n",
       " SoftmaxGlobal Pooling+ + +(a)MLP\n",
       " (b)FCN\n",
       " (C)ResNetFig. 1. The network structure of three tested neural networks. Dash line indicates the operation of dropout.\n",
       " the Class Activation Map (CAM) to ﬁnd out the contributing\n",
       " region in the raw data for the speciﬁc labels.\n",
       " II. N ETWORK ARCHITECTURES\n",
       " We tested three deep neural network architectures to provide\n",
       " a fully comprehensive baseline.\n",
       " A. Multilayer Perceptrons\n",
       " Our plain baselines are basic MLP by stacking three fully-\n",
       " connected layers. The fully-connected layers each has 500\n",
       " neurons following two design rules: (i) using dropout [11]\n",
       " at each layer’s input to improve the generalization capability ;\n",
       " and (ii) the non-linearity is fulﬁlled by the rectiﬁed linear unit\n",
       " (ReLU)[12] as the activation function to prevent saturation of\n",
       " the gradient when the network is deep. The network ends with\n",
       " a softmax layer. A basic layer block is formalized as\n",
       " ~x=fdropout;p (x)\n",
       " y=W\u0001~ x+b\n",
       " h=ReLU (y) (1)\n",
       " This architecture is mostly distinguished from the seminal\n",
       " MLP decades ago by the utilization of ReLU and dropout.\n",
       " ReLU helps to stack the networks deeper and dropout largely\n",
       " prevent the co-adaption of the neurons to help the model\n",
       " generalizes well especially on some small datasets. However,\n",
       " if the network is too deep, most neuron will hibernate as the\n",
       " ReLU totally halve the negative part. The Leaky ReLU [13]\n",
       " might help, but we only use three layers MLP with the ReLU\n",
       " to provide a fundamental baselines. The dropout rates at theinput layer, hidden layers and the softmax layer are f0.1, 0.2,\n",
       " 0.3g, respectively (Figure 1(a)).\n",
       " B. Fully Convolutional Networks\n",
       " FCN has shown compelling quality and efﬁciency for se-\n",
       " mantic segmentation on images [14]. Each output pixel is a\n",
       " classiﬁer corresponding to the receptive ﬁeld and the networks\n",
       " can thus be trained pixel-to-pixel given the category-wise\n",
       " semantic segmentation annotation.\n",
       " In our problem settings, the FCN is performed as a feature\n",
       " extractor. Its ﬁnal output still comes from the softmax layer.\n",
       " The basic block is a convolutional layer followed by a batch\n",
       " normalization layer [15] and a ReLU activation layer. The\n",
       " convolution operation is fulﬁlled by three 1-D kernels with the\n",
       " sizesf8;5;3gwithout striding. The basic convolution block\n",
       " is\n",
       " y=W\n",
       " x+b\n",
       " s=B,metadata = {'page': 2, '/Author': '', '/CreationDate': 'D:20161215013614Z', '/Creator': 'LaTeX with hyperref package', '/Keywords': '', '/ModDate': 'D:20161215013614Z', '/PTEX.Fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', '/Producer': 'pdfTeX-1.40.12', '/Subject': '', '/Title': '', '/Trapped': '/False', 'category': 'FILE', 'node_height': 0, 'node_length': 1}, prev_node = 4da3af91-c4ae-4ef6-bcb9-46d9e75ae0a9, next_node = a66c2eb4-8413-44e8-b216-150d46d1de35, parent_node = None, child_node = []),\n",
       " TextNode(id = a66c2eb4-8413-44e8-b216-150d46d1de35,text = N(y)\n",
       " h=ReLU (s) (2)\n",
       " \n",
       " is the convolution operator. We build the ﬁnal networks\n",
       " by stacking three convolution blocks with the ﬁlter sizes f128,\n",
       " 256, 128gin each block. Unlike the MCNN and MC-CNN, We\n",
       " exclude any pooling operation. This strategy is also adopted in\n",
       " the ResNet [16] as to prevent overﬁtting. Batch normalization\n",
       " is applied to speed up the convergence speed and help improve\n",
       " generalization. After the convolution blocks, the features are\n",
       " fed into a global average pooling layer [17] instead of a fully,metadata = {'page': 2, '/Author': '', '/CreationDate': 'D:20161215013614Z', '/Creator': 'LaTeX with hyperref package', '/Keywords': '', '/ModDate': 'D:20161215013614Z', '/PTEX.Fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', '/Producer': 'pdfTeX-1.40.12', '/Subject': '', '/Title': '', '/Trapped': '/False', 'category': 'FILE', 'node_height': 0, 'node_length': 1}, prev_node = 2777e78e-dfe1-4344-a931-cdc857f60b71, next_node = e5b93900-1544-4bc6-b059-a6262a80cf3f, parent_node = None, child_node = []),\n",
       " TextNode(id = e5b93900-1544-4bc6-b059-a6262a80cf3f,text = connected layer, which largely reduces the number of weights.\n",
       " The ﬁnal label is produced by a softmax layer (Figure 1(b)).\n",
       " C. Residual Network\n",
       " ResNet extends the neural networks to a very deep structures\n",
       " by adding the shortcut connection in each residual block to\n",
       " enable the gradient ﬂow directly through the bottom layers.\n",
       " It achieves the state-of-the-art performance in object detection\n",
       " and other vision related tasks [16]. We explore the ResNet\n",
       " structure since we are really interested to see how the very\n",
       " deep neural networks perform on the time series data. Ob-\n",
       " viously, the ResNet overﬁts the training data much easier\n",
       " because the datasets in UCR is comparatively small and lack\n",
       " of enough variants to learn the complex structures with such\n",
       " deep networks, but it is still a good practice to import the\n",
       " much deeper model and analyze the pros and cons.\n",
       " We reuse the convolutional blocks in Equation 2 to build\n",
       " each residual block. Let Block kdenotes the convolutional\n",
       " block with the number of ﬁlters k, the residual block is\n",
       " formalized as\n",
       " h1=Block k1(x)\n",
       " h2=Block k2(h1)\n",
       " h3=Block k3(h2)\n",
       " y=h3+x\n",
       " ^h=ReLU (y) (3)\n",
       " The number of ﬁlters ki=f64;128;128g. The ﬁnal ResNet\n",
       " stacks three residual blocks and followed by a global average\n",
       " pooling layer and a softmax layer. As this setting simply reuses\n",
       " the structures of the FCN, certainly there are better structures\n",
       " for the problem, but our given structures are adequate to\n",
       " provide a qualiﬁed demonstration as a baseline (Figure 1(c)).\n",
       " III. E XPERIMENTS AND RESULTS\n",
       " A. Experiment Settings\n",
       " We test our proposed neural networks on the same subset\n",
       " of the UCR time series repository, which includes 44 distinct\n",
       " time series datasets, to compare with other benchmarks. All\n",
       " the dataset has been split into training and testing by default.\n",
       " The only preprocessing in our experiment is z-normalization\n",
       " on both training and test split with the mean and standard\n",
       " deviation of the training part for each dataset. The MLP is\n",
       " trained with Adadelta [18] with learning rate 0.1, \u001a= 0:95\n",
       " and\u000f= 1e\u00008. The FCN and ResNet are trained with Adam\n",
       " [19] with the learning rate 0.001, \n",
       " 1= 0:9;\n",
       " 2= 0:999 and\n",
       " \u000f= 1e\u00008. The loss function for all tested model is categorical\n",
       " cross entropy. We choose the best model that achieves the\n",
       " lowest training loss and report its performance on the test\n",
       " set. While this training setting tends to give us a overﬁtted\n",
       " conﬁguration and most likely to generalize poorly on the\n",
       " test set, we can see that our proposed networks generalize\n",
       " quite well. Unlike ,metadata = {'page': 3, '/Author': '', '/CreationDate': 'D:20161215013614Z', '/Creator': 'LaTeX with hyperref package', '/Keywords': '', '/ModDate': 'D:20161215013614Z', '/PTEX.Fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', '/Producer': 'pdfTeX-1.40.12', '/Subject': '', '/Title': '', '/Trapped': '/False', 'category': 'FILE', 'node_height': 0, 'node_length': 1}, prev_node = a66c2eb4-8413-44e8-b216-150d46d1de35, next_node = 27b44cd1-de9a-49b7-8c5e-c39fc676e296, parent_node = None, child_node = []),\n",
       " TextNode(id = 27b44cd1-de9a-49b7-8c5e-c39fc676e296,text = other benchmarks, our experiment excludes\n",
       " the hyperparameter tuning and cross validation to provide\n",
       " a most unbiased baseline. Such settings also largely reducethe complexity for training and deploying the deep learning\n",
       " models.1\n",
       " B. Evaluation\n",
       " Table I shows the results and a comprehensive comparison\n",
       " with eight other best benchmark methods. We report the test\n",
       " error rate from the best model trained with the minimum cross-\n",
       " entropy loss and the number of dataset on which it achieved\n",
       " the best performance. Some literature (like [9], [5]) also report\n",
       " the ranks and other ranking-based statistics to evaluate the\n",
       " performance and make the comparison, so we also provide\n",
       " the average rankings.\n",
       " However, neither the number of best-performed dataset\n",
       " or the ranking based statistics is an unbiased measurement\n",
       " to compare the performance. The number of best-performed\n",
       " dataset focuses on the top performance and is highly skewed.\n",
       " The ranking based statistics is highly sensitive to the model\n",
       " pools. ”Better than” as a comparative measurement is also\n",
       " skewed as the input models might arbitrarily changed. All\n",
       " those evaluation measures wipe out the factor of number of\n",
       " classes.\n",
       " We propose a simple evaluation measure, Mean Per-Class\n",
       " Error (MPCE) to evaluate the classiﬁcation performance of\n",
       " the speciﬁc models on multiple datasets. For a given model\n",
       " M=fmig, a dataset pool D=fdkgwith the number of class\n",
       " labelC=fckgand the corresponding error rate E=fekg,\n",
       " PCE k=ek\n",
       " ck\n",
       " MPCE i=1\n",
       " KX\n",
       " PCE k (4)\n",
       " krefers to each dataset and idenotes to each model. The\n",
       " intuition behind MPCE is simple: the expected error rate for a\n",
       " single class across all the datasets. By considering the number\n",
       " of classes, MPCE is more robust as a baseline criterion. A\n",
       " paired T-test on PCE identiﬁes if the differences of the MPCE\n",
       " are signiﬁcant across different models.\n",
       " C. Results and Analysis\n",
       " We select seven existing best methods2that claim the state-\n",
       " of-the-art results and published within recent three years: time\n",
       " series based on a bag-offeatures (TSBF), Elastic Ensemble\n",
       " (PROP), 1-NN Bag-Of-SFA-Symbols (BOSS) in Vector Space\n",
       " (BOSSVS), the Shapelet Ensemble (SE1) model, ﬂat-COTE\n",
       " (COTE) and multi-scale CNN (MCNN). Note that COTE is\n",
       " an ensemble model which combines the weighted votes over\n",
       " 35 different classiﬁers. BOSSVS is an ensemble of multiple\n",
       " BOSS models with different window length. 1NN-DTW is\n",
       " also included as a simple standard baseline. The training and\n",
       " deploying complexity of our models are small like 1NN-DTW\n",
       " 1The codes are availab,metadata = {'page': 3, '/Author': '', '/CreationDate': 'D:20161215013614Z', '/Creator': 'LaTeX with hyperref package', '/Keywords': '', '/ModDate': 'D:20161215013614Z', '/PTEX.Fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', '/Producer': 'pdfTeX-1.40.12', '/Subject': '', '/Title': '', '/Trapped': '/False', 'category': 'FILE', 'node_height': 0, 'node_length': 1}, prev_node = e5b93900-1544-4bc6-b059-a6262a80cf3f, next_node = f508f7e1-1c0b-42f4-9d14-cd54603e5b53, parent_node = None, child_node = []),\n",
       " TextNode(id = f508f7e1-1c0b-42f4-9d14-cd54603e5b53,text = le at https://github.com/cauchyturing/\n",
       " UCR Time Series Classiﬁcation Deep Learning Baseline [20].\n",
       " 2’Best’ means the overall performance is competitive and the model should\n",
       " achieve the best performance on at least 4 datasets (10% of the all the 44\n",
       " datasets).,metadata = {'page': 3, '/Author': '', '/CreationDate': 'D:20161215013614Z', '/Creator': 'LaTeX with hyperref package', '/Keywords': '', '/ModDate': 'D:20161215013614Z', '/PTEX.Fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', '/Producer': 'pdfTeX-1.40.12', '/Subject': '', '/Title': '', '/Trapped': '/False', 'category': 'FILE', 'node_height': 0, 'node_length': 1}, prev_node = 27b44cd1-de9a-49b7-8c5e-c39fc676e296, next_node = c100c873-5f4d-495c-b879-fe5693c32313, parent_node = None, child_node = []),\n",
       " TextNode(id = c100c873-5f4d-495c-b879-fe5693c32313,text = TABLE I\n",
       " TESTING ERROR AND THE MEAN PER -CLASS ERROR (MPCE) ON44 UCR TIME SERIES DATASET\n",
       " Err Rate DTW COTE MCNN BOSSVS PROP BOSS SE1 TSBF MLP FCN ResNet\n",
       " Adiac 0.396 0.233 0.231 0.302 0.353 0.22 0.373 0.245 0.248 0.143 0.174\n",
       " Beef 0.367 0.133 0.367 0.267 0.367 0.2 0.133 0.287 0.167 0.25 0.233\n",
       " CBF 0.003 0.001 0.002 0.001 0.002 0 0.01 0.009 0.14 0 0.006\n",
       " ChlorineCon 0.352 0.314 0.203 0.345 0.36 0.34 0.312 0.336 0.128 0.157 0.172\n",
       " CinCECGTorso 0.349 0.064 0.058 0.13 0.062 0.125 0.021 0.262 0.158 0.187 0.229\n",
       " Coffee 0 0 0.036 0.036 0 0 0 0.004 0 0 0\n",
       " CricketX 0.246 0.154 0.182 0.346 0.203 0.259 0.297 0.278 0.431 0.185 0.179\n",
       " CricketY 0.256 0.167 0.154 0.328 0.156 0.208 0.326 0.259 0.405 0.208 0.195\n",
       " CricketZ 0.246 0.128 0.142 0.313 0.156 0.246 0.277 0.263 0.408 0.187 0.187\n",
       " DiatomSizeR 0.033 0.082 0.023 0.036 0.059 0.046 0.069 0.126 0.036 0.07 0.069\n",
       " ECGFiveDays 0.232 0 0 0 0.178 0 0.055 0.183 0.03 0.015 0.045\n",
       " FaceAll 0.192 0.105 0.235 0.241 0.152 0.21 0.247 0.234 0.115 0.071 0.166\n",
       " FaceFour 0.17 0.091 0 0.034 0.091 0 0.034 0.051 0.17 0.068 0.068\n",
       " FacesUCR 0.095 0.057 0.063 0.103 0.063 0.042 0.079 0.09 0.185 0.052 0.042\n",
       " 50words 0.31 0.191 0.19 0.367 0.18 0.301 0.288 0.209 0.288 0.321 0.273\n",
       " ﬁsh 0.177 0.029 0.051 0.017 0.034 0.011 0.057 0.08 0.126 0.029 0.011\n",
       " GunPoint 0.093 0.007 0 0 0.007 0 0.06 0.011 0.067 0 0.007\n",
       " Haptics 0.623 0.488 0.53 0.584 0.584 0.536 0.607 0.488 0.539 0.449 0.495\n",
       " InlineSkate 0.616 0.551 0.618 0.573 0.567 0.511 0.653 0.603 0.649 0.589 0.635\n",
       " ItalyPower 0.05 0.036 0.03 0.086 0.039 0.053 0.053 0.096 0.034 0.03 0.04\n",
       " Lightning2 0.131 0.164 0.164 0.262 0.115 0.148 0.098 0.257 0.279 0.197 0.246\n",
       " Lightning7 0.274 0.247 0.219 0.288 0.233 0.342 0.274 0.262 0.356 0.137 0.164\n",
       " MALLAT 0.066 0.036 0.057 0.064 0.05 0.058 0.092 0.037 0.064 0.02 0.021\n",
       " MedicalImages 0.263 0.258 0.26 0.474 0.245 0.288 0.305 0.269 0.271 0.208 0.228\n",
       " MoteStrain 0.165 0.085 0.079 0.115 0.114 0.073 0.113 0.135 0.131 0.05 0.105\n",
       " NonInvThorax1 0.21 0.093 0.064 0.169 0.178 0.161 0.174 0.138 0.058 0.039 0.052\n",
       " NonInvThorax2 0.135 0.073 0.06 0.118 0.112 0.101 0.118 0.13 0.057 0.045 0.049\n",
       " OliveOil 0.167 0.1 0.133 0.133 0.133 0.1 0.133 0.09 0.60 0.167 0.133\n",
       " OSULeaf 0.409 0.145 0.271 0.074 0.194 0.012 0.273 0.329 0.43 0.012 0.021\n",
       " SonyAIBORobot 0.275 0.146 0.23 0.265 0.293 0.321 0.238 0.175 0.273 0.032 0.015\n",
       " SonyAIBORobotII 0.169 0.076 0.07 0.188 0.124 0.098 0.066 0.196 0.161 0.038 0.038\n",
       " StarLightCurves 0.093 0.031 0.023 0.096 0.079 0.021 0.093 0.022 0.043 0.033 0.029\n",
       " SwedishLeaf 0.208 0.046 0.066 0.141 ,metadata = {'page': 4, '/Author': '', '/CreationDate': 'D:20161215013614Z', '/Creator': 'LaTeX with hyperref package', '/Keywords': '', '/ModDate': 'D:20161215013614Z', '/PTEX.Fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', '/Producer': 'pdfTeX-1.40.12', '/Subject': '', '/Title': '', '/Trapped': '/False', 'category': 'FILE', 'node_height': 0, 'node_length': 1}, prev_node = f508f7e1-1c0b-42f4-9d14-cd54603e5b53, next_node = da872e60-8db3-4cf1-be5c-17682862d457, parent_node = None, child_node = []),\n",
       " TextNode(id = da872e60-8db3-4cf1-be5c-17682862d457,text = 0.085 0.072 0.12 0.075 0.107 0.034 0.042\n",
       " Symbols 0.05 0.046 0.049 0.029 0.049 0.032 0.083 0.034 0.147 0.038 0.128\n",
       " SyntheticControl 0.007 0 0.003 0.04 0.01 0.03 0.033 0.008 0.05 0.01 0\n",
       " Trace 0 0.01 0 0 0.01 0 0.05 0.02 0.18 0 0\n",
       " TwoLeadECG 0 0.015 0.001 0.015 0 0.004 0.029 0.001 0.147 0 0\n",
       " TwoPatterns 0.096 0 0.002 0.001 0.067 0.016 0.048 0.046 0.114 0.103 0\n",
       " UWaveX 0.272 0.196 0.18 0.27 0.199 0.241 0.248 0.164 0.232 0.246 0.213\n",
       " UWaveY 0.366 0.267 0.268 0.364 0.283 0.313 0.322 0.249 0.297 0.275 0.332\n",
       " UWaveZ 0.342 0.265 0.232 0.336 0.29 0.312 0.346 0.217 0.295 0.271 0.245\n",
       " wafer 0.02 0.001 0.002 0.001 0.003 0.001 0.002 0.004 0.004 0.003 0.003\n",
       " WordSynonyms 0.351 0.266 0.276 0.439 0.226 0.345 0.357 0.302 0.406 0.42 0.368\n",
       " yoga 0.164 0.113 0.112 0.169 0.121 0.081 0.159 0.149 0.145 0.155 0.142\n",
       " Win 3 8 7 5 4 13 4 4 2 18 8\n",
       " A VG Arithmetic ranking 8.205 3.682 3.932 7.318 5.545 4.614 7.455 6.614 7.909 3.977 4.386\n",
       " A VG geometric ranking 7.160 3.054 3.249 5.997 4.744 3.388 6.431 5.598 6.941 2.780 3.481\n",
       " MPCE 0.0397 0.0226 0.0241 0.0330 0.0304 0.0256 0.0302 0.0335 0.0407 0.0219 0.0231\n",
       " as their pipeline is all from scratch without any heavy pre-\n",
       " processing and data augmentations, while our baselines do not\n",
       " need feature crafting.\n",
       " In Table I, we provide four metrics to fully evaluate different\n",
       " approaches. FCN indicates the best performance on three\n",
       " metrics at the ﬁrst sight, while ResNet is also competitive\n",
       " on the MPCE score and rankings.\n",
       " In [9], [5], the authors proposed to validate the effectiveness\n",
       " of their models by Wilcoxon signed-rank test on the error\n",
       " rates. Instead, we choose the Wilcoxon rank-sum test as it can\n",
       " deal with the tie conditions among the error rates with the\n",
       " tie correction (Appenix Table II). The p-values in our case are\n",
       " quite different with the results reported by [9]. Except for MLPand DTW, all other approaches are ’linked’ together based on\n",
       " the p-value. It possibly because the model pool we choose are\n",
       " different and the ranking based statistics is very sensitive to\n",
       " the model pool and its size.\n",
       " The MPCE score is reported in the last row. FCN and\n",
       " MLP have the best and worse MPCE score respectively. The\n",
       " ResNet ranks 3rd among all the 11 models, just a little worse\n",
       " than COTE. A paired T-test of mean on the PCE score is\n",
       " performed to tell if the difference of MPCE is signiﬁcant\n",
       " (Appendix Table III). Interestingly, we found the difference\n",
       " of MPCE among COTE, MCNN, BOSS, FCN and ResNet\n",
       " are not signiﬁcant. These ﬁve approaches are clustered in the\n",
       " best group. Anal,metadata = {'page': 4, '/Author': '', '/CreationDate': 'D:20161215013614Z', '/Creator': 'LaTeX with hyperref package', '/Keywords': '', '/ModDate': 'D:20161215013614Z', '/PTEX.Fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', '/Producer': 'pdfTeX-1.40.12', '/Subject': '', '/Title': '', '/Trapped': '/False', 'category': 'FILE', 'node_height': 0, 'node_length': 1}, prev_node = c100c873-5f4d-495c-b879-fe5693c32313, next_node = 47028ad2-316f-4e8c-b685-e446b79dde54, parent_node = None, child_node = []),\n",
       " TextNode(id = 47028ad2-316f-4e8c-b685-e446b79dde54,text = ogously, the rest approaches are grouped into,metadata = {'page': 4, '/Author': '', '/CreationDate': 'D:20161215013614Z', '/Creator': 'LaTeX with hyperref package', '/Keywords': '', '/ModDate': 'D:20161215013614Z', '/PTEX.Fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', '/Producer': 'pdfTeX-1.40.12', '/Subject': '', '/Title': '', '/Trapped': '/False', 'category': 'FILE', 'node_height': 0, 'node_length': 1}, prev_node = da872e60-8db3-4cf1-be5c-17682862d457, next_node = 8cde1c8e-3b4a-494e-9951-a8c8417a15ea, parent_node = None, child_node = []),\n",
       " TextNode(id = 8cde1c8e-3b4a-494e-9951-a8c8417a15ea,text = Fig. 2. Models grouping by the paired T-test of means on the normalized PCE scores.\n",
       " two clusters based on the T-test results of the MPCE scores\n",
       " (Figure 2).\n",
       " In the best group, BOSS and COTE are all ensemble based\n",
       " models. MCNN exploit convolutional networks but requires\n",
       " heavy preprocessing in data transformation, downsampling and\n",
       " window slicing. Our proposed FCN and ResNet are able to\n",
       " classify time series from scratch and achieves the premium\n",
       " performance. Compared to FCN, ResNet tends to overﬁt the\n",
       " data much easier, but is still clustered in the ﬁrst group without\n",
       " signiﬁcant difference to other four best models. We also note\n",
       " that the proposed three-layer MLP achieves comparable results\n",
       " to 1NN-DTW without signiﬁcant difference. Recent advances\n",
       " on ReLU and dropout work quite well in our experiments to\n",
       " help the MLP gain the similar performance with the previous\n",
       " baseline.\n",
       " IV. L OCALIZE THE CONTRIBUTING REGIONS WITH CLASS\n",
       " ACTIVATION MAP\n",
       " Another beneﬁt of FCN with the global average pooling\n",
       " layer is its natural extension, the class activation map (CAM)\n",
       " to interpret the class-speciﬁc region in the data [23].\n",
       " For a given time series, let Sk(x)represent the activation of\n",
       " ﬁlterkin the last convolutional layer at temporal location x.\n",
       " For ﬁlterk, the output of the following global average pooling\n",
       " layer isfk=P\n",
       " xSk(x). Letwc\n",
       " kindicate the weight of the\n",
       " ﬁnal softmax function for the output from ﬁlter kand the class\n",
       " c, then the input of the ﬁnal softmax function is\n",
       " gc=X\n",
       " kwc\n",
       " kX\n",
       " xSk(x)\n",
       " =X\n",
       " kX\n",
       " xwc\n",
       " kSk(x)\n",
       " We can deﬁne Mcas the class activation map for class c,\n",
       " where each temporal element is given by\n",
       " Mc=X\n",
       " kwc\n",
       " kSk(x)\n",
       " HenceMc(x;y)directly indicates the importance of the\n",
       " activation at temporal location xileading to the classiﬁcation\n",
       " of a sequence of time series to class c. If the output of the last\n",
       " convolutional layer is not the same as the input, we can still\n",
       " identify the contributing regions most relevant to the particular\n",
       " category by simply upsampling the class activation map to the\n",
       " length of the input time series.In Figure 3, we show two examples of the CAMs output\n",
       " using the above approach. We can see that the discriminative\n",
       " regions of the time series for the right classes are highlighted.\n",
       " We also highlight the differences in the CAMs for the different\n",
       " labels. The contributing regions for different categories are\n",
       " different.\n",
       " On the ’CBF’ dataset, label 0 is determined mostly by the\n",
       " region where the sharp drop occurs. Sequences with label\n",
       " 1 have the signature pattern of a sharp ri,metadata = {'page': 5, '/Author': '', '/CreationDate': 'D:20161215013614Z', '/Creator': 'LaTeX with hyperref package', '/Keywords': '', '/ModDate': 'D:20161215013614Z', '/PTEX.Fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', '/Producer': 'pdfTeX-1.40.12', '/Subject': '', '/Title': '', '/Trapped': '/False', 'category': 'FILE', 'node_height': 0, 'node_length': 1}, prev_node = 47028ad2-316f-4e8c-b685-e446b79dde54, next_node = 2aeb53d9-8acd-404d-a371-ecd78987e72a, parent_node = None, child_node = []),\n",
       " TextNode(id = 2aeb53d9-8acd-404d-a371-ecd78987e72a,text = se followed by a\n",
       " smoothly down trending. For label 2, the neural network is\n",
       " address more attention on the long plateau occurs around the\n",
       " middle. The similar analysis is also applied to the contributing\n",
       " region on the ’StarLightCurve’ dataset. However, the label 0\n",
       " and label 1 are quite similar in shapes, so the contributing\n",
       " map of label 1 focus less on the smooth trends of drop down\n",
       " while label 0 attract the uniform attention as the signal is much\n",
       " smoother.\n",
       " The CAM provides a natural way to ﬁnd out the contributing\n",
       " region in the raw data for the speciﬁc labels. This enables\n",
       " classiﬁcation-trained convolutional networks to learn to local-\n",
       " ize without any extra effort. Class activation maps also allow\n",
       " us to visualize the predicted class scores on any given time\n",
       " series, highlighting the discriminative subsequences detected\n",
       " by the convolutional networks. CAM also provide a way to\n",
       " ﬁnd a possible explanation on how the convolutional networks\n",
       " work for the setting of classiﬁcation.\n",
       " V. D ISCUSSION\n",
       " A. Overﬁtting and Generalization\n",
       " Neural networks is a strong universal approximator which\n",
       " is known to overﬁt easily due to the large number of param-\n",
       " eters. In our experiments, the overﬁtting was expected to be\n",
       " signiﬁcant since the UCR time series data is small and we\n",
       " have no validation/test settings, only choose the model with\n",
       " the lowest training loss for test.\n",
       " However, our models generalize quite well given that the\n",
       " training accuracy are almost all 100%. Dropout improves\n",
       " the generalization capability of MLP by a large margin.\n",
       " For the family of convolutional networks, batch normaliza-\n",
       " tion is known to help improve both the training speed and\n",
       " generalization. Another important reason is we replace the\n",
       " fully-connected layer by the global average pooling layer\n",
       " before the softmax layer, which greatly reduces the amount of\n",
       " parameters. Thus, starting with the basic network structures\n",
       " without any data transformation and ensemble, our three,metadata = {'page': 5, '/Author': '', '/CreationDate': 'D:20161215013614Z', '/Creator': 'LaTeX with hyperref package', '/Keywords': '', '/ModDate': 'D:20161215013614Z', '/PTEX.Fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', '/Producer': 'pdfTeX-1.40.12', '/Subject': '', '/Title': '', '/Trapped': '/False', 'category': 'FILE', 'node_height': 0, 'node_length': 1}, prev_node = 8cde1c8e-3b4a-494e-9951-a8c8417a15ea, next_node = 93626d2d-6568-4e6c-8828-8c01aca6b4a9, parent_node = None, child_node = []),\n",
       " TextNode(id = 93626d2d-6568-4e6c-8828-8c01aca6b4a9,text = Label 0: 0.984 Label 1: 0.999 Label 2: 0.985\n",
       " Label 0: 0.822 Label 1: 0.987 Label 2: 0.999high\n",
       " LowFig. 3. The class activation mapping (CAM) technique allows the classiﬁcation-trained FCN to both classify the time series and localize class-speciﬁc\n",
       " regions in a single forward-pass. The plots give examples of the contributing regions of the ground truth label in the raw data on the ’CBF’ (above) and\n",
       " ’StarLightCurve’ (below) dataset. The number indicates the likelihood of the corresponding label.\n",
       " models provide very simple but strong baseline for time series\n",
       " classiﬁcation with the state-of-the-art performance.\n",
       " Another nuance of our results is that, deep neural networks\n",
       " work potentially quite well on small dataset as we expand their\n",
       " generalization by recent advances in the network structures and\n",
       " other technical tricks.\n",
       " B. Feature Visualization and Analysis\n",
       " We adopt the Gramian Angular Summation Field (GASF)\n",
       " [21] to visualize the ﬁlters/weights in the neural networks.\n",
       " Given a series X=fx1;x2;:::;x ng, we rescale Xso that all\n",
       " values fall in the interval [0;1]\n",
       " ~xi\n",
       " 0=xi\u0000min(X)\n",
       " max(X)\u0000min(X)(5)\n",
       " Then we can easily exploit the angular perspective by\n",
       " considering the trigonometric summation between each point\n",
       " to identify the correlation within different time intervals. The\n",
       " GASF are deﬁned as\n",
       " G=\u0002cos(\n",
       " i+\n",
       " j)\u0003\n",
       " (6)\n",
       " = ~X0\u0001~X\u0000p\n",
       " I\u0000~X20\n",
       " \u0001p\n",
       " I\u0000~X2 (7)\n",
       " Iis the unit row vector [1;1;:::;1]. By deﬁning the inner\n",
       " product<x;y> =x\u0001y\u0000p\n",
       " 1\u0000x2\u0001p\n",
       " 1\u0000y2and<x;y> =p\n",
       " 1\u0000x2\u0001y\u0000x\u0001p\n",
       " 1\u0000y2,GASF are actually quasi-Gramian\n",
       " matrices [<~x1;~x1>].We choose GASF because it provides an intuitive way to in-\n",
       " terpret the multi-scale correlation in 1-D space. G(i;jjji\u0000jj=k)\n",
       " encodes the cosine summation over the points with the striding\n",
       " stepk. The main diagonal Gi;iis the special case when k= 0\n",
       " which contains the original values.\n",
       " Figure 4 provides a visual demonstration of the ﬁlters in\n",
       " three tested models. The weights from the second and the\n",
       " last layer in MLP are very similar with clear structures and\n",
       " very little degradation occurring. The weights in the ﬁrst layer,\n",
       " generally, have the higher values than the following layers.\n",
       " The ﬁlters in FCN and ResNet are very similar. The\n",
       " convolution extracts the local features in the temporal axis,\n",
       " essentially like a weighted moving average that enhances\n",
       " several receptive ﬁelds with the nonlinear transformations by\n",
       " the ReLU. The sliding ﬁlters consider the dependencies among\n",
       " different time intervals and frequencies. The ﬁlters learned\n",
       " in the deeper layers are similar with thei,metadata = {'page': 6, '/Author': '', '/CreationDate': 'D:20161215013614Z', '/Creator': 'LaTeX with hyperref package', '/Keywords': '', '/ModDate': 'D:20161215013614Z', '/PTEX.Fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', '/Producer': 'pdfTeX-1.40.12', '/Subject': '', '/Title': '', '/Trapped': '/False', 'category': 'FILE', 'node_height': 0, 'node_length': 1}, prev_node = 2aeb53d9-8acd-404d-a371-ecd78987e72a, next_node = ece35e99-e29c-47ec-9bb0-e6750ac76951, parent_node = None, child_node = []),\n",
       " TextNode(id = ece35e99-e29c-47ec-9bb0-e6750ac76951,text = r preceding layers.\n",
       " This suggests the local patterns across multiple convolutional\n",
       " layers are seemingly homogeneous. Both the visualization and\n",
       " classiﬁcation performance indicates the effectiveness of the 1-\n",
       " D convolution.\n",
       " C. Deep and Shallow\n",
       " The exploration on the very deep architecture is interesting\n",
       " and informative. The ResNet model has 11 layers but still\n",
       " holds the premium performance. There are two factors that\n",
       " impact the performance of the ResNet. With shortcut con-\n",
       " nections, the gradients can ﬂow directly through the bottom,metadata = {'page': 6, '/Author': '', '/CreationDate': 'D:20161215013614Z', '/Creator': 'LaTeX with hyperref package', '/Keywords': '', '/ModDate': 'D:20161215013614Z', '/PTEX.Fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', '/Producer': 'pdfTeX-1.40.12', '/Subject': '', '/Title': '', '/Trapped': '/False', 'category': 'FILE', 'node_height': 0, 'node_length': 1}, prev_node = 93626d2d-6568-4e6c-8828-8c01aca6b4a9, next_node = e9d9f131-2a69-4932-9682-fe6c1d3d9a83, parent_node = None, child_node = []),\n",
       " TextNode(id = e9d9f131-2a69-4932-9682-fe6c1d3d9a83,text = (a)MLP\n",
       " (b)FCN\n",
       " (C)ResNetFig. 4. Visualization of the ﬁlters learned in MLP, FCN and ResNet on the Adiac dataset. For ResNet, the three visualized ﬁlters are from the ﬁrst, second\n",
       " and third convolution layers in each residual blocks.\n",
       " layers in the ResNet, which largely improve the interpretability\n",
       " of the model to learn some highly complex patterns in the\n",
       " data. Meanwhile, the much deeper models tend to overﬁt\n",
       " much easier, requiring more effort in regularizing the model\n",
       " to improve its generalization ability.\n",
       " In our experiments, the batch normalization and global\n",
       " average pooling have largely improved the performance in\n",
       " test data but still tend to overﬁt, as the patterns in the UCR\n",
       " dataset are comparably not so complex to catch. As a result,\n",
       " the test performance of the ResNet is not as good as FCN.\n",
       " When the data is larger and more complex, we encourage the\n",
       " exploration of the ResNet structure since it is more likely to\n",
       " ﬁnd a good trade-off between the strong interpretability and\n",
       " generalization.\n",
       " D. Classiﬁcation Semantics\n",
       " The benchmark approaches for time series classiﬁcation\n",
       " could be categorized into three groups: distance based, feature\n",
       " based and neural neural network based. The combination of\n",
       " distance and feature based approaches are also commonly\n",
       " explored to improve the performance. We are curious about\n",
       " the classiﬁcation behavior of different models as if they allperform similarly on the same dataset, or their feature space\n",
       " and learned classiﬁer are diverged.\n",
       " The semantics of different models are evaluated based on\n",
       " their PCE scores. We choose PCA to reduce the dimension\n",
       " because this simple linear transformation is able to preserves\n",
       " large pairwise distances. In Figure 5, the distance between\n",
       " three baseline models with other benchmarks are compar-\n",
       " atively large. which indicates the feature and classiﬁcation\n",
       " criterion learned in our models are good complement to other\n",
       " models.\n",
       " It is natural to see that FCN and ResNet are quite close with\n",
       " each other. The embedding of MLP is isolated into a single\n",
       " category, meaning its classiﬁcation behavior is quite different\n",
       " with other approaches. This inspires us that a synthesis of the\n",
       " feature learned by MLP and convolutional networks through\n",
       " a deep-and-wide model [22] might also improve the perfor-\n",
       " mance.\n",
       " VI. C ONCLUSIONS\n",
       " We provide a simple and strong baseline for time series\n",
       " classiﬁcation from scratch with deep neural networks. Our\n",
       " proposed baseline models are pure end-to-end without any,metadata = {'page': 7, '/Author': '', '/CreationDate': 'D:20161215013614Z', '/Creator': 'LaTeX with hyperref package', '/Keywords': '', '/ModDate': 'D:20161215013614Z', '/PTEX.Fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', '/Producer': 'pdfTeX-1.40.12', '/Subject': '', '/Title': '', '/Trapped': '/False', 'category': 'FILE', 'node_height': 0, 'node_length': 1}, prev_node = ece35e99-e29c-47ec-9bb0-e6750ac76951, next_node = d372c3fd-13c5-4cd1-8063-306f4277624f, parent_node = None, child_node = []),\n",
       " TextNode(id = d372c3fd-13c5-4cd1-8063-306f4277624f,text = Fig. 5. The PCE distribution of different approaches after dimension reduction through PCA.\n",
       " heavy preprocessing on the raw data or feature crafting. The\n",
       " FCN achieves premium performance to other state-of-the-\n",
       " art approaches. Our exploration on the much deeper neural\n",
       " networks with the ResNet structure also gets competitive\n",
       " performance under the same experiment settings. The global\n",
       " average pooling in our convolutional model enables the ex-\n",
       " ploitation of the Class Activation Map (CAM) to ﬁnd out the\n",
       " contributing region in the raw data for the speciﬁc labels. A\n",
       " simple MLP is found to be identical to the 1NN-DTW as\n",
       " the previous golden baseline. An overall analysis is provided\n",
       " to discuss the generalization of our models, learned features,\n",
       " network structures and the classiﬁcation semantics. Rather\n",
       " than ranking based criterion, MPCE is proposed as an unbiased\n",
       " measurement to evaluate the performance of multiple models\n",
       " on multiple datasets. Many research focus on time series\n",
       " classiﬁcation and recent effort is more and more lying on the\n",
       " deep learning approach for the related tasks. Our baseline, with\n",
       " simple protocol and small complexity for building and deploy-\n",
       " ing, provides a default choice for the real world application\n",
       " and a good starting point for the future research.\n",
       " REFERENCES\n",
       " [1] E. Keogh and C. A. Ratanamahatana, “Exact indexing of dynamic time\n",
       " warping,” Knowledge and information systems , vol. 7, no. 3, pp. 358–\n",
       " 386, 2005.\n",
       " [2] J. Lin, E. Keogh, L. Wei, and S. Lonardi, “Experiencing sax: a novel\n",
       " symbolic representation of time series,” Data Mining and knowledge\n",
       " discovery , vol. 15, no. 2, pp. 107–144, 2007.TABLE II\n",
       " APPENDIX : THE P -VALUES OF WILCOXON RANK -SUM TEST BETWEEN\n",
       " OUR BASELINE MODELS WITH OTHER APPROACHES .\n",
       " MLP FCN ResNet\n",
       " DTW 0.7575 0.0203 0.0245\n",
       " COTE 0.0040 0.8445 0.8347\n",
       " MCNN 0.0049 0.9834 0.9468\n",
       " BOSSVS 0.1385 0.1660 0.1887\n",
       " PROP 0.0616 0.2529 0.2360\n",
       " BOSS 0.0076 0.8905 0.8740\n",
       " SE1 0.1299 0.0604 0.0576\n",
       " TSBF 0.1634 0.0715 0.0811\n",
       " MLP / 0.0051 0.0049\n",
       " FCN 0.0051 / 0.9169\n",
       " ResNet 0.0049 0.9169 /\n",
       " [3] M. G. Baydogan, G. Runger, and E. Tuv, “A bag-of-features framework\n",
       " to classify time series,” IEEE transactions on pattern analysis and\n",
       " machine intelligence , vol. 35, no. 11, pp. 2796–2802, 2013.\n",
       " [4] P. Sch ¨afer, “The boss is concerned with time series classiﬁcation in the\n",
       " presence of noise,” Data Mining and Knowledge Discovery , vol. 29,\n",
       " no. 6, pp. 1505–1530, 2015.\n",
       " [5] P. Schafer, “Scalable time series classiﬁcation,” Data Mining and\n",
       " Knowledge Discovery , pp.,metadata = {'page': 8, '/Author': '', '/CreationDate': 'D:20161215013614Z', '/Creator': 'LaTeX with hyperref package', '/Keywords': '', '/ModDate': 'D:20161215013614Z', '/PTEX.Fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', '/Producer': 'pdfTeX-1.40.12', '/Subject': '', '/Title': '', '/Trapped': '/False', 'category': 'FILE', 'node_height': 0, 'node_length': 1}, prev_node = e9d9f131-2a69-4932-9682-fe6c1d3d9a83, next_node = 7b85532c-76ae-4ecb-b40c-2d45c9ab5907, parent_node = None, child_node = []),\n",
       " TextNode(id = 7b85532c-76ae-4ecb-b40c-2d45c9ab5907,text =  1–26, 2015.\n",
       " [6] J. Lines and A. Bagnall, “Time series classiﬁcation with ensembles\n",
       " of elastic distance measures,” Data Mining and Knowledge Discovery ,\n",
       " vol. 29, no. 3, pp. 565–592, 2015.\n",
       " [7] A. Bagnall, J. Lines, J. Hills, and A. Bostrom, “Time-series classiﬁcation\n",
       " with cote: the collective of transformation-based ensembles,” IEEE\n",
       " Transactions on Knowledge and Data Engineering , vol. 27, no. 9, pp.\n",
       " 2522–2535, 2015.\n",
       " [8] Y . Zheng, Q. Liu, E. Chen, Y . Ge, and J. L. Zhao, “Exploiting multi-\n",
       " channels deep convolutional neural networks for multivariate time series,metadata = {'page': 8, '/Author': '', '/CreationDate': 'D:20161215013614Z', '/Creator': 'LaTeX with hyperref package', '/Keywords': '', '/ModDate': 'D:20161215013614Z', '/PTEX.Fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', '/Producer': 'pdfTeX-1.40.12', '/Subject': '', '/Title': '', '/Trapped': '/False', 'category': 'FILE', 'node_height': 0, 'node_length': 1}, prev_node = d372c3fd-13c5-4cd1-8063-306f4277624f, next_node = b644a979-7b3b-4775-a754-6793876d8e59, parent_node = None, child_node = []),\n",
       " TextNode(id = b644a979-7b3b-4775-a754-6793876d8e59,text = TABLE III\n",
       " APPENDIX : THE P -VALUES OF THE PAIRED T-TEST OF THE MEANS FOR THE MPCE SCORE ON 11BENCHMARK MODELS .\n",
       " DTW COTE MCNN BOSSVS PROP BOSS SE1 TSBF MLP FCN ResNet\n",
       " DTW 2.056E-05 5.699E-05 5.141E-02 4.832E-05 2.760E-04 3.040E-03 1.311E-02 4.234E-01 1.451E-04 3.427E-04\n",
       " COTE 2.287E-01 3.721E-05 5.911E-03 1.033E-01 1.208E-04 3.528E-04 5.240E-05 3.978E-01 4.351E-01\n",
       " MCNN 3.652E-04 1.354E-02 2.497E-01 3.634E-03 3.360E-03 8.023E-05 2.495E-01 3.757E-01\n",
       " BOSSVS 2.140E-01 6.404E-04 1.763E-01 4.335E-01 4.628E-02 2.983E-03 5.067E-03\n",
       " PROP 3.739E-02 4.654E-01 1.440E-01 2.061E-02 2.673E-02 4.241E-02\n",
       " BOSS 2.871E-02 1.759E-02 1.049E-03 1.879E-01 2.751E-01\n",
       " SE1 1.770E-01 9.901E-03 1.208E-02 3.251E-02\n",
       " TSBF 7.088E-02 1.510E-03 1.640E-03\n",
       " MLP 6.832E-05 3.045E-04\n",
       " FCN 2.508E-01\n",
       " ResNet\n",
       " classiﬁcation,” Frontiers of Computer Science , vol. 10, no. 1, pp. 96–\n",
       " 112, 2016.\n",
       " [9] Z. Cui, W. Chen, and Y . Chen, “Multi-scale convolutional neural net-\n",
       " works for time series classiﬁcation,” arXiv preprint arXiv:1603.06995 ,\n",
       " 2016.\n",
       " [10] Y . Chen, E. Keogh, B. Hu, N. Begum, A. Bagnall, A. Mueen, and\n",
       " G. Batista, “The ucr time series classiﬁcation archive (2015),” 2016.\n",
       " [11] N. Srivastava, G. E. Hinton, A. Krizhevsky, I. Sutskever, and\n",
       " R. Salakhutdinov, “Dropout: a simple way to prevent neural networks\n",
       " from overﬁtting.” Journal of Machine Learning Research , vol. 15, no. 1,\n",
       " pp. 1929–1958, 2014.\n",
       " [12] V . Nair and G. E. Hinton, “Rectiﬁed linear units improve restricted boltz-\n",
       " mann machines,” in Proceedings of the 27th International Conference\n",
       " on Machine Learning (ICML-10) , 2010, pp. 807–814.\n",
       " [13] B. Xu, N. Wang, T. Chen, and M. Li, “Empirical evaluation of rectiﬁed\n",
       " activations in convolutional network,” arXiv preprint arXiv:1505.00853 ,\n",
       " 2015.\n",
       " [14] J. Long, E. Shelhamer, and T. Darrell, “Fully convolutional networks\n",
       " for semantic segmentation,” in Proceedings of the IEEE Conference on\n",
       " Computer Vision and Pattern Recognition , 2015, pp. 3431–3440.\n",
       " [15] S. Ioffe and C. Szegedy, “Batch normalization: Accelerating deep\n",
       " network training by reducing internal covariate shift,” arXiv preprint\n",
       " arXiv:1502.03167 , 2015.\n",
       " [16] K. He, X. Zhang, S. Ren, and J. Sun, “Deep residual learning for image\n",
       " recognition,” arXiv preprint arXiv:1512.03385 , 2015.\n",
       " [17] M. Lin, Q. Chen, and S. Yan, “Network in network,” arXiv preprint\n",
       " arXiv:1312.4400 , 2013.\n",
       " [18] M. D. Zeiler, “Adadelta: an adaptive learning rate method,” arXiv\n",
       " preprint arXiv:1212.5701 , 2012.\n",
       " [19] D. Kingma and J. Ba, “Adam: A method for stochastic optimization,”,metadata = {'page': 9, '/Author': '', '/CreationDate': 'D:20161215013614Z', '/Creator': 'LaTeX with hyperref package', '/Keywords': '', '/ModDate': 'D:20161215013614Z', '/PTEX.Fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', '/Producer': 'pdfTeX-1.40.12', '/Subject': '', '/Title': '', '/Trapped': '/False', 'category': 'FILE', 'node_height': 0, 'node_length': 1}, prev_node = 7b85532c-76ae-4ecb-b40c-2d45c9ab5907, next_node = 7a639a4f-e1da-4d70-b4c5-9406138a1e56, parent_node = None, child_node = []),\n",
       " TextNode(id = 7a639a4f-e1da-4d70-b4c5-9406138a1e56,text = \n",
       " arXiv preprint arXiv:1412.6980 , 2014.\n",
       " [20] F. Chollet, “Keras,” https://github.com/fchollet/keras, 2015.\n",
       " [21] Z. Wang and T. Oates, “Imaging time-series to improve classiﬁcation\n",
       " and imputation,” arXiv preprint arXiv:1506.00327 , 2015.\n",
       " [22] H.-T. Cheng, L. Koc, J. Harmsen, T. Shaked, T. Chandra, H. Aradhye,\n",
       " G. Anderson, G. Corrado, W. Chai, M. Ispir et al. , “Wide & deep\n",
       " learning for recommender systems,” in Proceedings of the 1st Workshop\n",
       " on Deep Learning for Recommender Systems . ACM, 2016, pp. 7–10.\n",
       " [23] B. Zhou, A. Khosla, A. Lapedriza, A. Oliva, and A. Torralba,\n",
       " “Learning deep features for discriminative localization,” arXiv preprint\n",
       " arXiv:1512.04150 , 2015.,metadata = {'page': 9, '/Author': '', '/CreationDate': 'D:20161215013614Z', '/Creator': 'LaTeX with hyperref package', '/Keywords': '', '/ModDate': 'D:20161215013614Z', '/PTEX.Fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', '/Producer': 'pdfTeX-1.40.12', '/Subject': '', '/Title': '', '/Trapped': '/False', 'category': 'FILE', 'node_height': 0, 'node_length': 1}, prev_node = b644a979-7b3b-4775-a754-6793876d8e59, next_node = None, parent_node = None, child_node = [])]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|hide\n",
    "#|eval: false\n",
    "loader = PDFLoader('datasets/papers_pdf')\n",
    "documents = loader.get_documents()\n",
    "images = loader.get_images(path = loader.path)\n",
    "bridge = DocumentBridge(documents, context = context)\n",
    "nodes = bridge.nodes(chunk_size = 2500)\n",
    "nodes\n",
    "#For images save surrounding image context for context + gpt/blip interpretation of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d399ffa9-9d01-4ce6-b19e-2f4120e3eeea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id = 2003612c-0a10-4a23-8af4-299c706b6e1a, name = Time Series Classiﬁcation from Scratch with Deep, metadata = {'page': 1, '/Author': '', '/CreationDate': 'D:20161215013614Z', '/Creator': 'LaTeX with hyperref package', '/Keywords': '', '/ModDate': 'D:20161215013614Z', '/PTEX.Fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', '/Producer': 'pdfTeX-1.40.12', '/Subject': '', '/Title': '', '/Trapped': '/False'}, n_nodes = 0),\n",
       " Document(id = e0ff8ceb-97ac-46ad-bb59-b80b2f468636, name = Time Series Classiﬁcation from Scratch with Deep, metadata = {'page': 2, '/Author': '', '/CreationDate': 'D:20161215013614Z', '/Creator': 'LaTeX with hyperref package', '/Keywords': '', '/ModDate': 'D:20161215013614Z', '/PTEX.Fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', '/Producer': 'pdfTeX-1.40.12', '/Subject': '', '/Title': '', '/Trapped': '/False'}, n_nodes = 0),\n",
       " Document(id = 74229fa9-8bc1-4ad8-ba4e-06cc802494b8, name = Time Series Classiﬁcation from Scratch with Deep, metadata = {'page': 3, '/Author': '', '/CreationDate': 'D:20161215013614Z', '/Creator': 'LaTeX with hyperref package', '/Keywords': '', '/ModDate': 'D:20161215013614Z', '/PTEX.Fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', '/Producer': 'pdfTeX-1.40.12', '/Subject': '', '/Title': '', '/Trapped': '/False'}, n_nodes = 0),\n",
       " Document(id = d87ec00d-b57a-4106-ae7d-1b0d904a64d2, name = Time Series Classiﬁcation from Scratch with Deep, metadata = {'page': 4, '/Author': '', '/CreationDate': 'D:20161215013614Z', '/Creator': 'LaTeX with hyperref package', '/Keywords': '', '/ModDate': 'D:20161215013614Z', '/PTEX.Fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', '/Producer': 'pdfTeX-1.40.12', '/Subject': '', '/Title': '', '/Trapped': '/False'}, n_nodes = 0),\n",
       " Document(id = 74b3e668-7ef0-4219-8bcf-4b460df22183, name = Time Series Classiﬁcation from Scratch with Deep, metadata = {'page': 5, '/Author': '', '/CreationDate': 'D:20161215013614Z', '/Creator': 'LaTeX with hyperref package', '/Keywords': '', '/ModDate': 'D:20161215013614Z', '/PTEX.Fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', '/Producer': 'pdfTeX-1.40.12', '/Subject': '', '/Title': '', '/Trapped': '/False'}, n_nodes = 0),\n",
       " Document(id = 040171c5-8940-401f-8377-1012a75da1c5, name = Time Series Classiﬁcation from Scratch with Deep, metadata = {'page': 6, '/Author': '', '/CreationDate': 'D:20161215013614Z', '/Creator': 'LaTeX with hyperref package', '/Keywords': '', '/ModDate': 'D:20161215013614Z', '/PTEX.Fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', '/Producer': 'pdfTeX-1.40.12', '/Subject': '', '/Title': '', '/Trapped': '/False'}, n_nodes = 0),\n",
       " Document(id = 7f4bff90-3433-483b-b6d2-1a0ed941c7b2, name = Time Series Classiﬁcation from Scratch with Deep, metadata = {'page': 7, '/Author': '', '/CreationDate': 'D:20161215013614Z', '/Creator': 'LaTeX with hyperref package', '/Keywords': '', '/ModDate': 'D:20161215013614Z', '/PTEX.Fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', '/Producer': 'pdfTeX-1.40.12', '/Subject': '', '/Title': '', '/Trapped': '/False'}, n_nodes = 0),\n",
       " Document(id = bdf62a68-3dc2-4889-a2c1-c9cfae668fa6, name = Time Series Classiﬁcation from Scratch with Deep, metadata = {'page': 8, '/Author': '', '/CreationDate': 'D:20161215013614Z', '/Creator': 'LaTeX with hyperref package', '/Keywords': '', '/ModDate': 'D:20161215013614Z', '/PTEX.Fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', '/Producer': 'pdfTeX-1.40.12', '/Subject': '', '/Title': '', '/Trapped': '/False'}, n_nodes = 0),\n",
       " Document(id = cbee58e7-6c90-4cdf-b0b3-648cab99c7c2, name = Time Series Classiﬁcation from Scratch with Deep, metadata = {'page': 9, '/Author': '', '/CreationDate': 'D:20161215013614Z', '/Creator': 'LaTeX with hyperref package', '/Keywords': '', '/ModDate': 'D:20161215013614Z', '/PTEX.Fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', '/Producer': 'pdfTeX-1.40.12', '/Subject': '', '/Title': '', '/Trapped': '/False'}, n_nodes = 0)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|hide\n",
    "#|eval: false\n",
    "store = DocumentStore(documents)\n",
    "ids = store.ids()\n",
    "store.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cdd428-3ac7-4ba4-9284-b263f98054e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|eval: false\n",
    "# Maybe I can make it so the bridge knows if an object is a Node or a Doc when inputting it and serves for both. \n",
    "documents = store.get()\n",
    "bridge = DocumentBridge(documents, context = context)\n",
    "nodes = bridge.nodes()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2411c4-df1a-4a5b-8259-6666f6ef15cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f46c1a-060e-4a3a-b761-12f53c733bea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cfe06c-ab4c-45d2-a68c-2aa5cca8896b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a4a378-177c-43b0-8b05-ed573ec0f410",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba3c177-be06-47fd-ac69-d2ce2c3efd36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
