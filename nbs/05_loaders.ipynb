{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8404bfc-069b-49b4-b140-49c850418b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fc954c-662d-4ac0-96f2-84bcb70a8950",
   "metadata": {},
   "source": [
    "# Loaders\n",
    "\n",
    "> A module for importing data and converting it to a processable output for the most typical file formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aef0a0e-b785-4395-8f52-8c42e9998aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from pathlib import Path\n",
    "from pypdf import PdfReader\n",
    "import random\n",
    "from typing import List, Union\n",
    "import uuid\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import sys, platform, os\n",
    "from nanorag.context import ModelContext\n",
    "from nanorag.base import Document, TextNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee48c660-a2f3-4984-b1ec-43f15d7d2666",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nanorag.store import DocumentStore\n",
    "from nanorag.llm import LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f679303-536a-42ac-a5a0-e62315cbaccc",
   "metadata": {},
   "source": [
    "#|hide\n",
    "We have a set of PDF files we previously downloaded to test out and create a PDF loader. We will try to create a loader that extract both images and text in an structured way.\n",
    "\n",
    "\n",
    "Make it so it supports extracting tables, try mupdf and pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8099616f-6a84-4c8c-ac35-09f4df9cbf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#For simplicity lets start with accepting a List. \n",
    "class PDFLoader:\n",
    "    \"\"\"Accepts a dir or single path and converts its contents into documents that can be later used for storage and retrieval\"\"\"\n",
    "    def __init__(self, path_dir: str, store = None):\n",
    "        self.path_dir = Path(path_dir)\n",
    "        if self.path_dir.is_dir():\n",
    "            self.paths = [path for path in self.path_dir.iterdir() if path]\n",
    "        else:\n",
    "            self.paths = [self.path_dir]\n",
    "        self.path = None\n",
    "        self.store = store\n",
    "\n",
    "    def get_tables(self, path = None):\n",
    "        pass\n",
    "        \n",
    "    def pdf_validator(self, path):\n",
    "        \"\"\"Tries to read the pdf and returns a Bool value with the result\"\"\"\n",
    "        try:\n",
    "            reader = PdfReader(path)\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            return False\n",
    "\n",
    "    def load_random_pdf(self):\n",
    "        \"\"\"Load a random pdf from the dataset. It loads pdfs until a valid one is found\"\"\"\n",
    "        valid_pdf_found = False\n",
    "        while not valid_pdf_found:  # Continue until a valid PDF is found\n",
    "            pdf_path = random.choice(self.paths)\n",
    "            is_valid = self.pdf_validator(pdf_path)\n",
    "            if is_valid:\n",
    "                reader = PdfReader(pdf_path)\n",
    "                valid_pdf_found = True\n",
    "                self.path = pdf_path\n",
    "                return reader\n",
    "            else:\n",
    "                pdf_path.unlink()\n",
    "                self.paths.remove(pdf_path)  # Remove the invalid path from the list\n",
    "        \n",
    "        if not valid_pdf_found:\n",
    "            return None\n",
    "    def load_pdf(self, path):\n",
    "        reader = PdfReader(path)\n",
    "        self.path = path\n",
    "        return reader\n",
    "    \n",
    "    def format_reader_metadata(self, reader, include_local_path = True):\n",
    "        #Format the metadata of the pdf. \n",
    "        keys_to_include = [\"title\", \"author\", \"subject\",\"creator\", \"producer\",\"creation_date\", \"modification_date\"]\n",
    "        formatted_metadata = {}\n",
    "        for key in keys_to_include:\n",
    "            pdf_key = \"/\" + key.capitalize()\n",
    "            formatted_metadata[pdf_key] = getattr(reader.metadata, key, '')\n",
    "        if include_local_path:\n",
    "            formatted_metadata['file_path'] = self.path\n",
    "            formatted_metadata['file_name'] = self.path.name\n",
    "            # Retrieve and add system information\n",
    "            formatted_metadata['/SystemInfo'] = {\n",
    "                'os_type': platform.system(),\n",
    "                'working_directory': os.getcwd()\n",
    "            }\n",
    "        return formatted_metadata\n",
    "    \n",
    "    def get_documents(self, path = None):\n",
    "        \"\"\"Get a List of Text Documents from a pdf Path.\"\"\"\n",
    "        documents = []\n",
    "        #Extracting text and storing it in documents\n",
    "        source_id = self.__generate_id()\n",
    "        if path == None:\n",
    "            reader = self.load_random_pdf()\n",
    "        else:\n",
    "            reader = self.load_pdf(path)\n",
    "\n",
    "        formatted_metadata = self.format_reader_metadata(reader)\n",
    "        for i, page in enumerate(reader.pages):\n",
    "            params = {\"metadata\": {**{\"page\": i + 1, \"category\": \"PDF\"}, **formatted_metadata}, \"text\": page.extract_text(), \"source_id\": source_id}\n",
    "            #Add option to handle where it comes from\n",
    "            if i == 0:\n",
    "                title = formatted_metadata.get('/Title', None)\n",
    "                if title is None:\n",
    "                    title = params['text'].split('\\n')[0]        \n",
    "            if title is not None:\n",
    "                params[\"name\"] = title\n",
    "            doc = Document(**params)\n",
    "            doc.store = self.store\n",
    "            documents.append(doc)\n",
    "        return documents\n",
    "    def get_images(self, path = None):\n",
    "        #Can add some metadata like what page and location was found on. \n",
    "        #Create Image Node with that kind of info. \n",
    "        if path == None:\n",
    "            reader = self.load_random_pdf()\n",
    "        else:\n",
    "            reader = self.load_pdf(path)\n",
    "        images = []\n",
    "        for count, page in enumerate(reader.pages):\n",
    "            for image_file_object in page.images:\n",
    "                image = Image.open(BytesIO(image_file_object.data))\n",
    "                images.append(image)\n",
    "        return images\n",
    "    def __generate_id(self):\n",
    "        return str(uuid.uuid4())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f068f724-47ea-4192-9986-d340776d8c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class DocumentBridge:\n",
    "    \"\"\"Class for connecting a list of documents into its corresponding Nodes and relationships\"\"\"\n",
    "    def __init__(self, documents: Union[List[Document], Document], context: ModelContext):\n",
    "        if isinstance(documents, List):\n",
    "            self.documents = documents\n",
    "        else:\n",
    "            self.documents = [documents]\n",
    "        self.context = context\n",
    "    def to_nodes(self, chunk_size = 1024) -> List[TextNode]:\n",
    "        \"\"\"Brige a series of Documents into nodes linked by the end and start of the prev and next document. Great for linking together complex docs with structure\n",
    "        such as pages or other info extracted first on a Document basis.\"\"\"\n",
    "        doc_nodes_list = [doc.create_nodes_from_doc(model_context = self.context, chunk_size = chunk_size) for doc in self.documents]\n",
    "        if len(doc_nodes_list) > 1:\n",
    "            for i, node_list in enumerate(doc_nodes_list):\n",
    "                if i == 0:\n",
    "                    node_list[-1].next_node = doc_nodes_list[i + 1][0].id\n",
    "                else:\n",
    "                    if i < len(doc_nodes_list) - 1:\n",
    "                        node_list[-1].next_node = doc_nodes_list[i + 1][0].id\n",
    "                    node_list[0].prev_node = doc_nodes_list[i - 1][-1].id\n",
    "            nodes = [node for node_list in doc_nodes_list for node in node_list]\n",
    "        elif len(doc_nodes_list) == 1:\n",
    "            nodes = doc_nodes_list[0]\n",
    "            for i, node in enumerate(nodes):\n",
    "                if i == 0:\n",
    "                    node.prev_node = None\n",
    "                else:\n",
    "                    node.prev_node = nodes[i - 1].id\n",
    "                    if i < len(nodes) - 1:\n",
    "                        node.next_node = nodes[i + 1].id\n",
    "        return nodes\n",
    "        \n",
    "    def to_doc(self, include_children = False, \n",
    "               separator = '\\n-----------------------------------------------------------------------------------------\\n') -> Document:\n",
    "        \"\"\"Bridges a series of Documents into a single document. Great for storing sub-documents into a single one. Keeps some metadata of the documents into one. \n",
    "        Use documents with the same source id to be included here. \"\"\"\n",
    "        text = ''\n",
    "        for i, doc in enumerate(self.documents):\n",
    "            text += doc.text + separator\n",
    "        metadata = self.documents[0].metadata;metadata.pop('page', None); metadata['pages'] = i + 1    \n",
    "        document = Document(name = self.documents[0].name, text = text, metadata = metadata,\n",
    "                            source_id = self.documents[0].source_id, doc_separator = separator, store = self.documents[0].store)\n",
    "        if include_children:\n",
    "            subdocument_ids = [subdoc.id for subdoc in self.documents] #This would be children.\n",
    "            document.child_node= subdocument_ids\n",
    "        return document\n",
    "    def to_subdocs(self):\n",
    "        \"\"\"Split a document based on its separator. It will split them by pages by default. Each\n",
    "        page ends with a specific separator.\"\"\"\n",
    "        if len(self.documents) == 1:\n",
    "            single_document = self.documents[0]\n",
    "        else:\n",
    "            raise ValueError('Only one document can be converted to subdocuments')\n",
    "        separator = single_document.doc_separator\n",
    "        split_text = single_document.text.split(separator)\n",
    "        split_text = [text for i, text in enumerate(split_text) if text != '']\n",
    "        metadata = single_document.metadata\n",
    "        documents = []\n",
    "        for i, doc in enumerate(split_text):\n",
    "            document = Document(text = doc, name = single_document.name + f': {i + 1}', metadata = metadata.copy(), source_id=single_document.source_id, store = single_document.store)\n",
    "            document.metadata.pop('pages', None)\n",
    "            document.metadata['page'] = i + 1\n",
    "            if i != 0:\n",
    "                document.prev_node = documents[i - 1].id\n",
    "                documents[i - 1].next_node = document.id\n",
    "            documents.append(document)\n",
    "        return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9448a0f8-8817-4b41-9d1e-13e7f57d1c33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a3531af525c48298807ad62a2f1e18e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| hide\n",
    "#|eval: false\n",
    "context = ModelContext()\n",
    "context.set_default()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b246bb-f801-412d-96d3-54d06dcf39b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|eval: false\n",
    "loader = PDFLoader('datasets/papers_pdf')\n",
    "documents = loader.get_documents()\n",
    "images = loader.get_images(path = loader.path)\n",
    "bridge = DocumentBridge(documents, context = context)\n",
    "nodes = bridge.to_nodes(chunk_size = 2500)\n",
    "#For images save surrounding image context for context + gpt/blip interpretation of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d399ffa9-9d01-4ce6-b19e-2f4120e3eeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|eval: false\n",
    "source_id = documents[0].source_id\n",
    "store = DocumentStore(documents)\n",
    "ids = store.ids()\n",
    "subdocuments = store.group_by_source_id(source_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41170745",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|eval: false\n",
    "single_document = DocumentBridge(subdocuments, context = context).to_doc(include_children = True)\n",
    "nodes = DocumentBridge(single_document, context=context).to_nodes(chunk_size = 2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d37752",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|eval: false\n",
    "subdocuments = DocumentBridge(single_document, context=context).to_subdocs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2411c4-df1a-4a5b-8259-6666f6ef15cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
