{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6102c907-3669-4272-9629-9bd172bf08eb",
   "metadata": {},
   "source": [
    "# Store\n",
    "\n",
    "> Provides storage for documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97efea1c-7f06-4dce-97db-4861dbae1c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdcc0a7-d360-41d3-8687-3312cd1c2638",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from nanorag.base import Document, abstractmethod, ABC\n",
    "from nanorag.context import ModelContext\n",
    "from nanorag.loaders import PDFLoader, DocumentBridge\n",
    "from typing import Union, List, Dict, Optional\n",
    "from uuid import UUID\n",
    "from collections import defaultdict\n",
    "from psycopg2.extensions import AsIs\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237fdf61-9e4c-49f9-aeae-4ba3d78ea0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class BaseDocumentStore(ABC):\n",
    "    \"\"\"\n",
    "    Base class for document storage\"\"\"\n",
    "    def __init__(self, documents : Dict[str, Document] = {}):\n",
    "        pass\n",
    "    @abstractmethod    \n",
    "    def add(self, document: Document):\n",
    "        pass\n",
    "    @abstractmethod \n",
    "    def ids(self):\n",
    "        pass\n",
    "    @abstractmethod    \n",
    "    def delete(self, ids: Union[List, str]):\n",
    "        pass\n",
    "    @abstractmethod\n",
    "    def get(self, ids: Union[UUID, List]):\n",
    "        pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17538f0-ad16-43fc-9686-55824ce404a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class DocumentStore(BaseDocumentStore):\n",
    "    \"\"\"Key value type document store that store documents by their id in a dictionary.\n",
    "    Also checks for duplicates via hashing and doesn't admit them. Compatible with both nodes and documents.\"\"\"\n",
    "    def __init__(self, documents : Union[List[Document], Document]= []):\n",
    "        if isinstance(documents, list):\n",
    "            self.documents = {document.id: document for document in documents}\n",
    "        elif isinstance(documents, Document):\n",
    "            self.documents = {documents.id: documents}\n",
    "\n",
    "        \n",
    "    def add(self, document: Union[List[Document], Document]) -> str:\n",
    "        doc_ids = []\n",
    "        if isinstance(document, list):\n",
    "            for doc in document:\n",
    "                self.add(doc)\n",
    "                doc_ids.append(doc.id)\n",
    "        else:\n",
    "            for stored_document in self.documents:\n",
    "                if self.documents[stored_document].hash == document.hash:\n",
    "                    return f\"You tried to add a duplicate document: {document.hash}\"\n",
    "                elif self.documents[stored_document].id == document.id:\n",
    "                    self.documents[document.id] = document\n",
    "                    return f\"Document with id {document.id} has been updated\"\n",
    "            self.documents[document.id] =  document\n",
    "        return f\"The following documents have been added: {doc_ids}\"\n",
    "\n",
    "    def ids(self):\n",
    "        doc_ids = [doc for doc in self.documents]\n",
    "        return doc_ids\n",
    "\n",
    "    def delete(self, ids: Union[List, str]):\n",
    "        deleted_docs = []\n",
    "        if isinstance(ids, List):\n",
    "            for id in ids:\n",
    "                deleted_doc = self.documents.pop(id, None)\n",
    "                if deleted_doc != None:\n",
    "                    deleted_docs.append(deleted_doc)\n",
    "        elif isinstance(ids, UUID):\n",
    "            deleted_doc = self.documents.pop(ids, None)\n",
    "            print(f'Ids are: {ids} and theoretically deleted doc is {deleted_doc}')\n",
    "            if deleted_doc != None:\n",
    "                deleted_docs.append(deleted_doc)\n",
    "        return f\"The following docs have been deleted {deleted_docs}\"\n",
    "        \n",
    "    def get(self, ids: Optional[Union[List[UUID], UUID]] = None) -> Optional[Union[Document, List[Document]]]:\n",
    "        if ids == None:\n",
    "            ids = self.ids()\n",
    "            if isinstance(ids, List):\n",
    "                if len(ids) == 0:\n",
    "                    return None\n",
    "        if isinstance(ids, List):\n",
    "            docs = [self.documents[id] for id in ids if id in self.documents]\n",
    "            if len(docs) == 0:\n",
    "                return None\n",
    "            return docs\n",
    "        elif isinstance(ids, UUID):\n",
    "            doc = self.documents.get(ids, None)\n",
    "            if doc is None:\n",
    "                return None\n",
    "            return doc\n",
    "        return None\n",
    "    def group_by_source_id(self, source_id = None): #Other type of filters can be added\n",
    "        grouped_documents = defaultdict(list)\n",
    "        for doc in self.documents.values():\n",
    "            if source_id == None:\n",
    "                grouped_documents[doc.source_id].append(doc)\n",
    "            elif doc.source_id not in grouped_documents or doc.source_id == source_id:\n",
    "                grouped_documents[doc.source_id].append(doc)\n",
    "        if source_id != None:\n",
    "            return grouped_documents[source_id]\n",
    "        return dict(grouped_documents)\n",
    "#NOTE: Could I store both nodes and docs in same store? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7460f65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import psycopg2\n",
    "import os\n",
    "db_uri = os.environ.get('POSTGRES_URI', None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f579136",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "#TODO: Handle doc modifications and sync with nodes.\n",
    "\n",
    "class PostgresDocumentStore(BaseDocumentStore):\n",
    "    \n",
    "    def __init__(self,db_uri, table_name = 'documents'):\n",
    "        self.table_name = table_name\n",
    "        self.schema_name = 'public'\n",
    "        self.conn = psycopg2.connect(db_uri)\n",
    "        self.cur = self.conn.cursor()\n",
    "        self.__create_if_not_exists()\n",
    "\n",
    "    def add(self, documents: Union[List[Document], Document]):\n",
    "        #TODO: Handle the case of a duplicate and a matching hash.\n",
    "        if isinstance(documents, Document):\n",
    "            documents = [documents]\n",
    "\n",
    "        if isinstance(documents, list):\n",
    "            docs_to_insert = [\n",
    "            (\n",
    "                str(doc.id), \n",
    "                str(doc.source_id), \n",
    "                doc.name, \n",
    "                doc.text.replace('\\x00', ''),  # Remove null bytes\n",
    "                json.dumps(doc.metadata), \n",
    "                doc.hash,\n",
    "                doc.metadata.get('category', 'UNCATEGORIZED'),\n",
    "                doc.doc_separator\n",
    "            ) \n",
    "            for doc in documents\n",
    "            ]\n",
    "            try:\n",
    "                self.cur.executemany(f\"\"\"\n",
    "                INSERT INTO {self.table_name} (id, source_id, name, text, metadata, hash, category, doc_separator)\n",
    "                VALUES (%s, %s, %s, %s, %s, %s, %s, %s);\n",
    "                \"\"\",docs_to_insert)\n",
    "                self.conn.commit()\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred: {str(e)}\")\n",
    "                return None\n",
    "        doc_ids = [doc[0] for doc in docs_to_insert]\n",
    "        return f\"The following documents have been added: {doc_ids}\"\n",
    "        #For now not including any relationship\n",
    "    def ids(self):\n",
    "        try:\n",
    "            self.cur.execute(f\"\"\"\n",
    "            SELECT id\n",
    "            FROM {self.schema_name}.{self.table_name};\n",
    "            \"\"\")\n",
    "            result = self.cur.fetchall()\n",
    "            if len(result) == 0:\n",
    "                return None\n",
    "            return [doc[0] for doc in result]\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {str(e)}\")\n",
    "            return None\n",
    "    def delete(self, ids: Union[List[str], str]):\n",
    "        \n",
    "        pass\n",
    "    def get(self, ids : Optional[Union[str, List[str]]] = None):\n",
    "        def convert_to_doc(result): \n",
    "            id, source_id, name, text, metadata, category, doc_separator = result\n",
    "            doc = Document(id = id, source_id = source_id, name = name, text = text, metadata = metadata, \n",
    "                            doc_separator = doc_separator)\n",
    "            doc.metadata['category'] = category\n",
    "            return doc\n",
    "        if ids:\n",
    "            try:\n",
    "                if isinstance(ids, str):\n",
    "                    ids = [ids]\n",
    "                if isinstance(ids, list):\n",
    "                    ids = ids\n",
    "                self.cur.execute(f\"\"\"SELECT id, source_id, name, text, metadata, category, doc_separator\n",
    "                                    FROM {self.schema_name}.{self.table_name}\n",
    "                                    WHERE id = ANY(%s::uuid[]);\"\"\", (ids,))\n",
    "                result = self.cur.fetchall()\n",
    "                if len(result) == 0:\n",
    "                    return None\n",
    "                documents = [convert_to_doc(doc) for doc in result]\n",
    "                return documents\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred: {str(e)}\")\n",
    "                return None\n",
    "        else:\n",
    "            try:\n",
    "                self.cur.execute(f\"\"\"\n",
    "                SELECT id, source_id, name, text, metadata, category, doc_separator\n",
    "                FROM {self.schema_name}.{self.table_name};\n",
    "                \"\"\")\n",
    "                result = self.cur.fetchall()\n",
    "                if len(result) == 0:\n",
    "                    return None\n",
    "                documents = [convert_to_doc(doc) for doc in result]\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred: {str(e)}\")\n",
    "                return None\n",
    "            return documents\n",
    "\n",
    "    def __enter__(self):\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, exc_type, exc_value, traceback):\n",
    "        self.close()\n",
    "\n",
    "    def __create_if_not_exists(self):\n",
    "        \"\"\"\n",
    "        Creates a table for storing documents if it doesn't exist in the database,\n",
    "        returns True if the table already exists and False if it was just created. \n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.cur.execute(f\"\"\"\n",
    "                SELECT EXISTS (\n",
    "                SELECT FROM pg_tables\n",
    "                WHERE  schemaname = '{self.schema_name}'\n",
    "                AND    tablename  = '{self.table_name}'\n",
    "                );\n",
    "                \"\"\")\n",
    "\n",
    "            table_exists = self.cur.fetchone()[0]\n",
    "\n",
    "            if not table_exists:\n",
    "                print('Does not exist')\n",
    "                self.cur.execute(f\"\"\"\n",
    "                CREATE TABLE {self.table_name} (\n",
    "                    id UUID PRIMARY KEY,\n",
    "                    source_id UUID NOT NULL,\n",
    "                    name TEXT,\n",
    "                    text TEXT NOT NULL,\n",
    "                    metadata JSONB,\n",
    "                    hash TEXT UNIQUE NOT NULL,\n",
    "                    prev_node UUID,\n",
    "                    next_node UUID,\n",
    "                    category VARCHAR(255),\n",
    "                    doc_separator VARCHAR(255),\n",
    "                    FOREIGN KEY (prev_node) REFERENCES {self.table_name}(id),\n",
    "                    FOREIGN KEY (next_node) REFERENCES {self.table_name}(id));\n",
    "                \"\"\")\n",
    "                self.conn.commit()\n",
    "                return False\n",
    "            else:\n",
    "                return True\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {str(e)}\")\n",
    "            return None\n",
    "        \n",
    "    def close(self): #To use the syntax, with PostgresDocumentStore(db_uri) as store:\n",
    "        if self.cur is not None:\n",
    "            self.cur.close()\n",
    "        if self.conn is not None:\n",
    "            self.conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df853036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e02a1214abd24afe942284e68f9b406e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| hide \n",
    "#| eval: false\n",
    "context = ModelContext()\n",
    "context.set_default()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c998806b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "#| eval: false\n",
    "store = PostgresDocumentStore(db_uri)\n",
    "loader = PDFLoader('datasets/papers_pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf70a5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The following documents have been added: ['428403e3-2621-44a9-a904-c35387b7c8b5']\""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide \n",
    "#| eval: false\n",
    "documents = loader.get_documents()\n",
    "single_document = DocumentBridge(documents, context).to_doc() #Make a pipeline for this\n",
    "store.add(single_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ae14fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "#| eval: false\n",
    "documents = store.get('31bc4a75-7dc5-47b8-9023-05346674134a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bc4491",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "#| eval: false\n",
    "\n",
    "def convert_to_doc(result):\n",
    "    id, source_id, name, text, metadata, category, doc_separator = result\n",
    "    doc = Document(id = id, source_id = source_id, name = name, text = text, metadata = metadata, \n",
    "                    doc_separator = doc_separator)\n",
    "    doc.metadata['category'] = category\n",
    "    return doc\n",
    "doc = convert_to_doc(documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6d989b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69d9d7fe276140818ad96a2dc219e83b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| hide \n",
    "#| eval: false\n",
    "context = ModelContext()\n",
    "context.set_default()\n",
    "documents = loader.get_documents()\n",
    "single_document = DocumentBridge(documents, context).to_doc()\n",
    "store.add(single_document)\n",
    "subdocs = DocumentBridge(single_document, context).to_subdocuments() #Getting this we can convert to nodes. Can be similar for meetings. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05418738",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "#| eval: false\n",
    "import os\n",
    "import psycopg2\n",
    "db_uri = os.environ['POSTGRES_URI']\n",
    "conn = psycopg2.connect(db_uri)\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a3ed18-b244-4d1f-a6a0-a24a03c01521",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af49de6d",
   "metadata": {},
   "source": [
    "Example insert into DocStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebffaddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| eval: false\n",
    "loader = PDFLoader('datasets/papers_pdf')\n",
    "documents = loader.get_documents()\n",
    "store = DocumentStore(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153b5e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| eval: false\n",
    "documents_2 = loader.get_documents()\n",
    "store.add(documents_2)\n",
    "source_id = documents_2[0].source_id\n",
    "document = store.group_by_source_id(source_id)\n",
    "document"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
